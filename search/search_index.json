{"config":{"lang":["en","zh","ja","pt"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Warning</p> <p>We assume no responsibility for any illegal use of the codebase. Please refer to the local laws regarding DMCA (Digital Millennium Copyright Act) and other relevant laws in your area.  This codebase and all models are released under the CC-BY-NC-SA-4.0 license.</p> <p> </p>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>GPU Memory: 4GB (for inference), 8GB (for fine-tuning)</li> <li>System: Linux, Windows</li> </ul>"},{"location":"#windows-setup","title":"Windows Setup","text":"<p>Professional Windows users may consider using WSL2 or Docker to run the codebase.</p> <pre><code># Create a python 3.10 virtual environment, you can also use virtualenv\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# Install pytorch\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n\n# Install fish-speech\npip3 install -e .\n\n# (Enable acceleration) Install triton-windows\npip install https://github.com/AnyaCoder/fish-speech/releases/download/v0.1.0/triton_windows-0.1.0-py3-none-any.whl\n</code></pre> <p>Non-professional Windows users can consider the following basic methods to run the project without a Linux environment (with model compilation capabilities, i.e., <code>torch.compile</code>):</p> <ol> <li>Extract the project package.</li> <li>Click <code>install_env.bat</code> to install the environment.</li> <li>If you want to enable compilation acceleration, follow this step:<ol> <li>Download the LLVM compiler from the following links:<ul> <li>LLVM-17.0.6 (Official Site Download)</li> <li>LLVM-17.0.6 (Mirror Site Download)</li> <li>After downloading <code>LLVM-17.0.6-win64.exe</code>, double-click to install, select an appropriate installation location, and most importantly, check the <code>Add Path to Current User</code> option to add the environment variable.</li> <li>Confirm that the installation is complete.</li> </ul> </li> <li>Download and install the Microsoft Visual C++ Redistributable to solve potential .dll missing issues:<ul> <li>MSVC++ 14.40.33810.0 Download</li> </ul> </li> <li>Download and install Visual Studio Community Edition to get MSVC++ build tools and resolve LLVM's header file dependencies:<ul> <li>Visual Studio Download</li> <li>After installing Visual Studio Installer, download Visual Studio Community 2022.</li> <li>As shown below, click the <code>Modify</code> button and find the <code>Desktop development with C++</code> option to select and download.</li> </ul> </li> <li>Download and install CUDA Toolkit 12.x</li> </ol> </li> <li>Double-click <code>start.bat</code> to open the training inference WebUI management interface. If needed, you can modify the <code>API_FLAGS</code> as prompted below.</li> </ol> <p>Optional</p> <p>Want to start the inference WebUI? </p> <p>Edit the <code>API_FLAGS.txt</code> file in the project root directory and modify the first three lines as follows:  <pre><code> --infer \n # --api \n # --listen ...\n ...\n</code></pre></p> <p>Optional</p> <p>Want to start the API server? </p> <p>Edit the <code>API_FLAGS.txt</code> file in the project root directory and modify the first three lines as follows:</p> <pre><code># --infer\n--api\n--listen ...\n...\n</code></pre> <p>Optional</p> <p>Double-click <code>run_cmd.bat</code> to enter the conda/python command line environment of this project.</p>"},{"location":"#linux-setup","title":"Linux Setup","text":"<pre><code># Create a python 3.10 virtual environment, you can also use virtualenv\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# Install pytorch\npip3 install torch torchvision torchaudio\n\n# Install fish-speech\npip3 install -e .[stable]\n\n# (Ubuntu / Debian User) Install sox\napt install libsox-dev\n</code></pre>"},{"location":"#changelog","title":"Changelog","text":"<ul> <li>2024/09/10: Updated Fish-Speech to 1.4 version, with an increase in dataset size and a change in the quantizer's n_groups from 4 to 8.</li> <li>2024/07/02: Updated Fish-Speech to 1.2 version, remove VITS Decoder, and greatly enhanced zero-shot ability.</li> <li>2024/05/10: Updated Fish-Speech to 1.1 version, implement VITS decoder to reduce WER and improve timbre similarity.</li> <li>2024/04/22: Finished Fish-Speech 1.0 version, significantly modified VQGAN and LLAMA models.</li> <li>2023/12/28: Added <code>lora</code> fine-tuning support.</li> <li>2023/12/27: Add <code>gradient checkpointing</code>, <code>causual sampling</code>, and <code>flash-attn</code> support.</li> <li>2023/12/19: Updated webui and HTTP API.</li> <li>2023/12/18: Updated fine-tuning documentation and related examples.</li> <li>2023/12/17: Updated <code>text2semantic</code> model, supporting phoneme-free mode.</li> <li>2023/12/13: Beta version released, includes VQGAN model and a language model based on LLAMA (phoneme support only).</li> </ul>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<ul> <li>VITS2 (daniilrobnikov)</li> <li>Bert-VITS2</li> <li>GPT VITS</li> <li>MQTTS</li> <li>GPT Fast</li> <li>Transformers</li> <li>GPT-SoVITS</li> </ul>"},{"location":"finetune/","title":"Fine-tuning","text":"<p>Obviously, when you opened this page, you were not satisfied with the performance of the few-shot pre-trained model. You want to fine-tune a model to improve its performance on your dataset.</p> <p>In current version, you only need to finetune the 'LLAMA' part.</p>"},{"location":"finetune/#fine-tuning-llama","title":"Fine-tuning LLAMA","text":""},{"location":"finetune/#1-prepare-the-dataset","title":"1. Prepare the dataset","text":"<pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u2514\u2500\u2500 30.1-32.71.mp3\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u2514\u2500\u2500 38.79-40.85.mp3\n</code></pre> <p>You need to convert your dataset into the above format and place it under <code>data</code>. The audio file can have the extensions <code>.mp3</code>, <code>.wav</code>, or <code>.flac</code>, and the annotation file should have the extensions <code>.lab</code>.</p> <p>Warning</p> <p>It's recommended to apply loudness normalization to the dataset. You can use fish-audio-preprocess to do this.</p> <pre><code>fap loudness-norm data-raw data --clean\n</code></pre>"},{"location":"finetune/#2-batch-extraction-of-semantic-tokens","title":"2. Batch extraction of semantic tokens","text":"<p>Make sure you have downloaded the VQGAN weights. If not, run the following command:</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>You can then run the following command to extract semantic tokens:</p> <pre><code>python tools/vqgan/extract_vq.py data \\\n    --num-workers 1 --batch-size 16 \\\n    --config-name \"firefly_gan_vq\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>Note</p> <p>You can adjust <code>--num-workers</code> and <code>--batch-size</code> to increase extraction speed, but please make sure not to exceed your GPU memory limit. For the VITS format, you can specify a file list using <code>--filelist xxx.list</code>.</p> <p>This command will create <code>.npy</code> files in the <code>data</code> directory, as shown below:</p> <pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 21.15-26.44.npy\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.npy\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u251c\u2500\u2500 30.1-32.71.mp3\n\u2502   \u2514\u2500\u2500 30.1-32.71.npy\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u251c\u2500\u2500 38.79-40.85.mp3\n    \u2514\u2500\u2500 38.79-40.85.npy\n</code></pre>"},{"location":"finetune/#3-pack-the-dataset-into-protobuf","title":"3. Pack the dataset into protobuf","text":"<pre><code>python tools/llama/build_dataset.py \\\n    --input \"data\" \\\n    --output \"data/protos\" \\\n    --text-extension .lab \\\n    --num-workers 16\n</code></pre> <p>After the command finishes executing, you should see the <code>quantized-dataset-ft.protos</code> file in the <code>data</code> directory.</p>"},{"location":"finetune/#4-finally-fine-tuning-with-lora","title":"4. Finally, fine-tuning with LoRA","text":"<p>Similarly, make sure you have downloaded the <code>LLAMA</code> weights. If not, run the following command:</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>Finally, you can start the fine-tuning by running the following command:</p> <pre><code>python fish_speech/train.py --config-name text2semantic_finetune \\\n    project=$project \\\n    +lora@model.model.lora_config=r_8_alpha_16\n</code></pre> <p>Note</p> <p>You can modify the training parameters such as <code>batch_size</code>, <code>gradient_accumulation_steps</code>, etc. to fit your GPU memory by modifying <code>fish_speech/configs/text2semantic_finetune.yaml</code>.</p> <p>Note</p> <p>For Windows users, you can use <code>trainer.strategy.process_group_backend=gloo</code> to avoid <code>nccl</code> issues.</p> <p>After training is complete, you can refer to the inference section, and use <code>--speaker SPK1</code> to generate speech.</p> <p>Info</p> <p>By default, the model will only learn the speaker's speech patterns and not the timbre. You still need to use prompts to ensure timbre stability. If you want to learn the timbre, you can increase the number of training steps, but this may lead to overfitting.</p> <p>After training, you need to convert the LoRA weights to regular weights before performing inference.</p> <pre><code>python tools/llama/merge_lora.py \\\n    --lora-config r_8_alpha_16 \\\n    --base-weight checkpoints/fish-speech-1.4 \\\n    --lora-weight results/$project/checkpoints/step_000000010.ckpt \\\n    --output checkpoints/fish-speech-1.4-yth-lora/\n</code></pre> <p>Note</p> <p>You may also try other checkpoints. We suggest using the earliest checkpoint that meets your requirements, as they often perform better on out-of-distribution (OOD) data.</p>"},{"location":"inference/","title":"Inference","text":"<p>Inference support command line, HTTP API and web UI.</p> <p>Note</p> <p>Overall, reasoning consists of several parts:</p> <ol> <li>Encode a given ~10 seconds of voice using VQGAN.</li> <li>Input the encoded semantic tokens and the corresponding text into the language model as an example.</li> <li>Given a new piece of text, let the model generate the corresponding semantic tokens.</li> <li>Input the generated semantic tokens into VITS / VQGAN to decode and generate the corresponding voice.</li> </ol>"},{"location":"inference/#command-line-inference","title":"Command Line Inference","text":"<p>Download the required <code>vqgan</code> and <code>llama</code> models from our Hugging Face repository.</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre>"},{"location":"inference/#1-generate-prompt-from-voice","title":"1. Generate prompt from voice:","text":"<p>Note</p> <p>If you plan to let the model randomly choose a voice timbre, you can skip this step.</p> <pre><code>python tools/vqgan/inference.py \\\n    -i \"paimon.wav\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>You should get a <code>fake.npy</code> file.</p>"},{"location":"inference/#2-generate-semantic-tokens-from-text","title":"2. Generate semantic tokens from text:","text":"<pre><code>python tools/llama/generate.py \\\n    --text \"The text you want to convert\" \\\n    --prompt-text \"Your reference text\" \\\n    --prompt-tokens \"fake.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --num-samples 2 \\\n    --compile\n</code></pre> <p>This command will create a <code>codes_N</code> file in the working directory, where N is an integer starting from 0.</p> <p>Note</p> <p>You may want to use <code>--compile</code> to fuse CUDA kernels for faster inference (~30 tokens/second -&gt; ~500 tokens/second). Correspondingly, if you do not plan to use acceleration, you can comment out the <code>--compile</code> parameter.</p> <p>Info</p> <p>For GPUs that do not support bf16, you may need to use the <code>--half</code> parameter.</p>"},{"location":"inference/#3-generate-vocals-from-semantic-tokens","title":"3. Generate vocals from semantic tokens:","text":""},{"location":"inference/#vqgan-decoder","title":"VQGAN Decoder","text":"<pre><code>python tools/vqgan/inference.py \\\n    -i \"codes_0.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre>"},{"location":"inference/#http-api-inference","title":"HTTP API Inference","text":"<p>We provide a HTTP API for inference. You can use the following command to start the server:</p> <pre><code>python -m tools.api \\\n    --listen 0.0.0.0:8080 \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>If you want to speed up inference, you can add the --compile parameter.</p> <p>After that, you can view and test the API at http://127.0.0.1:8080/.</p> <p>Below is an example of sending a request using <code>tools/post_api.py</code>.</p> <pre><code>python -m tools.post_api \\\n    --text \"Text to be input\" \\\n    --reference_audio \"Path to reference audio\" \\\n    --reference_text \"Text content of the reference audio\" \\\n    --streaming True\n</code></pre> <p>The above command indicates synthesizing the desired audio according to the reference audio information and returning it in a streaming manner.</p> <p>The following example demonstrates that you can use multiple reference audio paths and reference audio texts at once. Separate them with spaces in the command.</p> <pre><code>python -m tools.post_api \\\n    --text \"Text to input\" \\\n    --reference_audio \"reference audio path1\" \"reference audio path2\" \\\n    --reference_text \"reference audio text1\" \"reference audio text2\"\\\n    --streaming False \\\n    --output \"generated\" \\\n    --format \"mp3\"\n</code></pre> <p>The above command synthesizes the desired <code>MP3</code> format audio based on the information from multiple reference audios and saves it as <code>generated.mp3</code> in the current directory.</p>"},{"location":"inference/#gui-inference","title":"GUI Inference","text":"<p>Download client</p>"},{"location":"inference/#webui-inference","title":"WebUI Inference","text":"<p>You can start the WebUI using the following command:</p> <pre><code>python -m tools.webui \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>Note</p> <p>You can use Gradio environment variables, such as <code>GRADIO_SHARE</code>, <code>GRADIO_SERVER_PORT</code>, <code>GRADIO_SERVER_NAME</code> to configure WebUI.</p> <p>Enjoy!</p>"},{"location":"samples/","title":"Samples","text":"<p>v1.2 samples are available on Bilibili.</p> <p>The following samples are from the v1.1 model.</p>"},{"location":"samples/#chinese-sentence-1","title":"Chinese Sentence 1","text":"<pre><code>\u4eba\u95f4\u706f\u706b\u5012\u6620\u6e56\u4e2d\uff0c\u5979\u7684\u6e34\u671b\u8ba9\u9759\u6c34\u6cdb\u8d77\u6d9f\u6f2a\u3002\u82e5\u4ee3\u4ef7\u53ea\u662f\u5b64\u72ec\uff0c\u90a3\u5c31\u8ba9\u8fd9\u4efd\u613f\u671b\u8086\u610f\u6d41\u6dcc\u3002\n\u6d41\u5165\u5979\u6240\u6ce8\u89c6\u7684\u4e16\u95f4\uff0c\u4e5f\u6d41\u5165\u5979\u5982\u6e56\u6c34\u822c\u6f84\u6f88\u7684\u76ee\u5149\u3002\n</code></pre> Speaker Input Audio Synthesized Audio Nahida (Genshin Impact) Zhongli (Genshin Impact) Furina (Genshin Impact) Random Speaker 1  -  Random Speaker 2  -"},{"location":"samples/#chinese-sentence-2","title":"Chinese Sentence 2","text":"<pre><code>\u4f60\u4eec\u8fd9\u4e2a\u662f\u4ec0\u4e48\u7fa4\u554a\uff0c\u4f60\u4eec\u8fd9\u662f\u5bb3\u4eba\u4e0d\u6d45\u554a\u4f60\u4eec\u8fd9\u4e2a\u7fa4\uff01\u8c01\u662f\u7fa4\u4e3b\uff0c\u51fa\u6765\uff01\u771f\u7684\u592a\u8fc7\u5206\u4e86\u3002\u4f60\u4eec\u641e\u8fd9\u4e2a\u7fa4\u5e72\u4ec0\u4e48\uff1f\n\u6211\u513f\u5b50\u6bcf\u4e00\u79d1\u7684\u6210\u7ee9\u90fd\u4e0d\u8fc7\u90a3\u4e2a\u5e73\u5747\u5206\u5450\uff0c\u4ed6\u73b0\u5728\u521d\u4e8c\uff0c\u4f60\u53eb\u6211\u513f\u5b50\u600e\u4e48\u529e\u554a\uff1f\u4ed6\u73b0\u5728\u8fd8\u4e0d\u5230\u9ad8\u4e2d\u554a\uff1f\n\u4f60\u4eec\u5bb3\u6b7b\u6211\u513f\u5b50\u4e86\uff01\u5feb\u70b9\u51fa\u6765\u4f60\u8fd9\u4e2a\u7fa4\u4e3b\uff01\u518d\u8fd9\u6837\u6211\u53bb\u62a5\u8b66\u4e86\u554a\uff01\u6211\u8ddf\u4f60\u4eec\u8bf4\u4f60\u4eec\u8fd9\u4e00\u5e2e\u4eba\u554a\uff0c\u4e00\u5929\u5230\u665a\u554a\uff0c\n\u641e\u8fd9\u4e9b\u4ec0\u4e48\u6e38\u620f\u554a\uff0c\u52a8\u6f2b\u554a\uff0c\u4f1a\u5bb3\u6b7b\u4f60\u4eec\u7684\uff0c\u4f60\u4eec\u6ca1\u6709\u524d\u9014\u6211\u8ddf\u4f60\u8bf4\u3002\u4f60\u4eec\u8fd9\u4e5d\u767e\u591a\u4e2a\u4eba\uff0c\u597d\u597d\u5b66\u4e60\u4e0d\u597d\u5417\uff1f\n\u4e00\u5929\u5230\u665a\u5728\u4e0a\u7f51\u3002\u6709\u4ec0\u4e48\u610f\u601d\u554a\uff1f\u9ebb\u70e6\u4f60\u91cd\u89c6\u4e00\u4e0b\u4f60\u4eec\u7684\u751f\u6d3b\u7684\u76ee\u6807\u554a\uff1f\u6709\u4e00\u70b9\u5b66\u4e60\u76ee\u6807\u884c\u4e0d\u884c\uff1f\u4e00\u5929\u5230\u665a\u4e0a\u7f51\u662f\u4e0d\u662f\u4eba\u554a\uff1f\n</code></pre> Speaker Input Audio Synthesized Audio Nahida (Genshin Impact) Random Speaker  -"},{"location":"samples/#chinese-sentence-3","title":"Chinese Sentence 3","text":"<pre><code>\u5927\u5bb6\u597d\uff0c\u6211\u662f Fish Audio \u5f00\u53d1\u7684\u5f00\u6e90\u6587\u672c\u8f6c\u8bed\u97f3\u6a21\u578b\u3002\u7ecf\u8fc7\u5341\u4e94\u4e07\u5c0f\u65f6\u7684\u6570\u636e\u8bad\u7ec3\uff0c\n\u6211\u5df2\u7ecf\u80fd\u591f\u719f\u7ec3\u638c\u63e1\u4e2d\u6587\u3001\u65e5\u8bed\u548c\u82f1\u8bed\uff0c\u6211\u7684\u8bed\u8a00\u5904\u7406\u80fd\u529b\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0c\u58f0\u97f3\u8868\u73b0\u5f62\u5f0f\u4e30\u5bcc\u591a\u53d8\u3002\n\u4f5c\u4e3a\u4e00\u4e2a\u4ec5\u6709\u4ebf\u7ea7\u53c2\u6570\u7684\u6a21\u578b\uff0c\u6211\u76f8\u4fe1\u793e\u533a\u6210\u5458\u80fd\u591f\u5728\u4e2a\u4eba\u8bbe\u5907\u4e0a\u8f7b\u677e\u8fd0\u884c\u548c\u5fae\u8c03\uff0c\u8ba9\u6211\u6210\u4e3a\u60a8\u7684\u79c1\u4eba\u8bed\u97f3\u52a9\u624b\u3002\n</code></pre> Speaker Input Audio Synthesized Audio Random Speaker  -"},{"location":"samples/#english-sentence-1","title":"English Sentence 1","text":"<pre><code>In the realm of advanced technology, the evolution of artificial intelligence stands as a \nmonumental achievement. This dynamic field, constantly pushing the boundaries of what \nmachines can do, has seen rapid growth and innovation. From deciphering complex data \npatterns to driving cars autonomously, AI's applications are vast and diverse.\n</code></pre> Speaker Input Audio Synthesized Audio Random Speaker 1  -  Random Speaker 2  -"},{"location":"samples/#english-sentence-2","title":"English Sentence 2","text":"<pre><code>Hello everyone, I am an open-source text-to-speech model developed by \nFish Audio. After training with 150,000 hours of data, I have become proficient \nin Chinese, Japanese, and English, and my language processing abilities \nare close to human level. My voice is capable of a wide range of expressions. \nAs a model with only hundreds of millions of parameters, I believe community \nmembers can easily run and fine-tune me on their personal devices, allowing \nme to serve as your personal voice assistant.\n</code></pre> Speaker Input Audio Synthesized Audio Random Speaker  -"},{"location":"samples/#japanese-sentence-1","title":"Japanese Sentence 1","text":"<pre><code>\u5148\u9032\u6280\u8853\u306e\u9818\u57df\u306b\u304a\u3044\u3066\u3001\u4eba\u5de5\u77e5\u80fd\u306e\u9032\u5316\u306f\u753b\u671f\u7684\u306a\u6210\u679c\u3068\u3057\u3066\u7acb\u3063\u3066\u3044\u307e\u3059\u3002\u5e38\u306b\u6a5f\u68b0\u304c\u3067\u304d\u308b\u3053\u3068\u306e\u9650\u754c\u3092\n\u62bc\u3057\u5e83\u3052\u3066\u3044\u308b\u3053\u306e\u30c0\u30a4\u30ca\u30df\u30c3\u30af\u306a\u5206\u91ce\u306f\u3001\u6025\u901f\u306a\u6210\u9577\u3068\u9769\u65b0\u3092\u898b\u305b\u3066\u3044\u307e\u3059\u3002\u8907\u96d1\u306a\u30c7\u30fc\u30bf\u30d1\u30bf\u30fc\u30f3\u306e\u89e3\u8aad\u304b\n\u3089\u81ea\u52d5\u904b\u8ee2\u8eca\u306e\u64cd\u7e26\u307e\u3067\u3001AI\u306e\u5fdc\u7528\u306f\u5e83\u7bc4\u56f2\u306b\u53ca\u3073\u307e\u3059\u3002\n</code></pre> Speaker Input Audio Synthesized Audio Random Speaker 1  -  Random Speaker 2  -"},{"location":"samples/#japanese-sentence-2","title":"Japanese Sentence 2","text":"<pre><code>\u7686\u3055\u3093\u3001\u3053\u3093\u306b\u3061\u306f\u3002\u79c1\u306f\u30d5\u30a3\u30c3\u30b7\u30e5\u30aa\u30fc\u30c7\u30a3\u30aa\u306b\u3088\u3063\u3066\u958b\u767a\u3055\u308c\u305f\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u306e\u30c6\n\u30ad\u30b9\u30c8\u304b\u3089\u97f3\u58f0\u3078\u306e\u5909\u63db\u30e2\u30c7\u30eb\u3067\u3059\u300215\u4e07\u6642\u9593\u306e\u30c7\u30fc\u30bf\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u7d4c\u3066\u3001\n\u4e2d\u56fd\u8a9e\u3001\u65e5\u672c\u8a9e\u3001\u82f1\u8a9e\u3092\u719f\u77e5\u3057\u3066\u304a\u308a\u3001\u8a00\u8a9e\u51e6\u7406\u80fd\u529b\u306f\u4eba\u9593\u306b\u8fd1\u3044\u30ec\u30d9\u30eb\u3067\u3059\u3002\n\u58f0\u306e\u8868\u73fe\u3082\u591a\u5f69\u3067\u8c4a\u304b\u3067\u3059\u3002\u6570\u5104\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6301\u3064\u3053\u306e\u30e2\u30c7\u30eb\u306f\u3001\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\n\u306e\u30e1\u30f3\u30d0\u30fc\u304c\u500b\u4eba\u306e\u30c7\u30d0\u30a4\u30b9\u3067\u7c21\u5358\u306b\u5b9f\u884c\u3057\u3001\u5fae\u8abf\u6574\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3068\n\u4fe1\u3058\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u79c1\u3092\u500b\u4eba\u306e\u97f3\u58f0\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3068\u3057\u3066\u6d3b\u7528\u3067\u304d\u307e\u3059\u3002\n</code></pre> Speaker Input Audio Synthesized Audio Random Speaker  -"},{"location":"zh/","title":"\u4ecb\u7ecd","text":"<p>Warning</p> <p>\u6211\u4eec\u4e0d\u5bf9\u4ee3\u7801\u5e93\u7684\u4efb\u4f55\u975e\u6cd5\u4f7f\u7528\u627f\u62c5\u4efb\u4f55\u8d23\u4efb. \u8bf7\u53c2\u9605\u60a8\u5f53\u5730\u5173\u4e8e DMCA (\u6570\u5b57\u5343\u5e74\u6cd5\u6848) \u548c\u5176\u4ed6\u76f8\u5173\u6cd5\u5f8b\u6cd5\u89c4.  \u6b64\u4ee3\u7801\u5e93\u4e0e\u6240\u6709\u6a21\u578b\u6839\u636e CC-BY-NC-SA-4.0 \u8bb8\u53ef\u8bc1\u53d1\u5e03.</p> <p> </p>"},{"location":"zh/#_2","title":"\u8981\u6c42","text":"<ul> <li>GPU \u5185\u5b58: 4GB (\u7528\u4e8e\u63a8\u7406), 8GB (\u7528\u4e8e\u5fae\u8c03)</li> <li>\u7cfb\u7edf: Linux, Windows</li> </ul>"},{"location":"zh/#windows","title":"Windows \u914d\u7f6e","text":"<p>Windows \u4e13\u4e1a\u7528\u6237\u53ef\u4ee5\u8003\u8651 WSL2 \u6216 docker \u6765\u8fd0\u884c\u4ee3\u7801\u5e93\u3002</p> <pre><code># \u521b\u5efa\u4e00\u4e2a python 3.10 \u865a\u62df\u73af\u5883, \u4f60\u4e5f\u53ef\u4ee5\u7528 virtualenv\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# \u5b89\u88c5 pytorch\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n\n# \u5b89\u88c5 fish-speech\npip3 install -e .\n\n# (\u5f00\u542f\u7f16\u8bd1\u52a0\u901f) \u5b89\u88c5 triton-windows\npip install https://github.com/AnyaCoder/fish-speech/releases/download/v0.1.0/triton_windows-0.1.0-py3-none-any.whl\n</code></pre> <p>Windows \u975e\u4e13\u4e1a\u7528\u6237\u53ef\u8003\u8651\u4ee5\u4e0b\u4e3a\u514d Linux \u73af\u5883\u7684\u57fa\u7840\u8fd0\u884c\u65b9\u6cd5\uff08\u9644\u5e26\u6a21\u578b\u7f16\u8bd1\u529f\u80fd\uff0c\u5373 <code>torch.compile</code>\uff09\uff1a</p> <ol> <li>\u89e3\u538b\u9879\u76ee\u538b\u7f29\u5305\u3002</li> <li>\u70b9\u51fb <code>install_env.bat</code> \u5b89\u88c5\u73af\u5883\u3002</li> <li>\u82e5\u9700\u8981\u5f00\u542f\u7f16\u8bd1\u52a0\u901f\u5219\u6267\u884c\u8fd9\u4e00\u6b65:<ol> <li>\u4f7f\u7528\u5982\u4e0b\u94fe\u63a5\u4e0b\u8f7d LLVM \u7f16\u8bd1\u5668\u3002<ul> <li>LLVM-17.0.6\uff08\u539f\u7ad9\u7ad9\u70b9\u4e0b\u8f7d\uff09</li> <li>LLVM-17.0.6\uff08\u955c\u50cf\u7ad9\u70b9\u4e0b\u8f7d\uff09</li> <li>\u4e0b\u8f7d\u5b8c <code>LLVM-17.0.6-win64.exe</code> \u540e\uff0c\u53cc\u51fb\u8fdb\u884c\u5b89\u88c5\uff0c\u9009\u62e9\u5408\u9002\u7684\u5b89\u88c5\u4f4d\u7f6e\uff0c\u6700\u91cd\u8981\u7684\u662f\u52fe\u9009 <code>Add Path to Current User</code> \u6dfb\u52a0\u73af\u5883\u53d8\u91cf\u3002</li> <li>\u786e\u8ba4\u5b89\u88c5\u5b8c\u6210\u3002</li> </ul> </li> <li>\u4e0b\u8f7d\u5b89\u88c5 Microsoft Visual C++ \u53ef\u518d\u53d1\u884c\u7a0b\u5e8f\u5305\uff0c\u89e3\u51b3\u6f5c\u5728 .dll \u4e22\u5931\u95ee\u9898\u3002<ul> <li>MSVC++ 14.40.33810.0 \u4e0b\u8f7d</li> </ul> </li> <li>\u4e0b\u8f7d\u5b89\u88c5 Visual Studio \u793e\u533a\u7248\u4ee5\u83b7\u53d6 MSVC++ \u7f16\u8bd1\u5de5\u5177, \u89e3\u51b3 LLVM \u7684\u5934\u6587\u4ef6\u4f9d\u8d56\u95ee\u9898\u3002<ul> <li>Visual Studio \u4e0b\u8f7d</li> <li>\u5b89\u88c5\u597d Visual Studio Installer \u4e4b\u540e\uff0c\u4e0b\u8f7d Visual Studio Community 2022</li> <li>\u5982\u4e0b\u56fe\u70b9\u51fb<code>\u4fee\u6539</code>\u6309\u94ae\uff0c\u627e\u5230<code>\u4f7f\u7528C++\u7684\u684c\u9762\u5f00\u53d1</code>\u9879\uff0c\u52fe\u9009\u4e0b\u8f7d</li> </ul> </li> <li>\u4e0b\u8f7d\u5b89\u88c5 CUDA Toolkit 12.x</li> </ol> </li> <li>\u53cc\u51fb <code>start.bat</code> \u6253\u5f00\u8bad\u7ec3\u63a8\u7406 WebUI \u7ba1\u7406\u754c\u9762. \u5982\u6709\u9700\u8981\uff0c\u53ef\u7167\u4e0b\u5217\u63d0\u793a\u4fee\u6539<code>API_FLAGS</code>.</li> </ol> <p>\u53ef\u9009</p> <p>\u60f3\u542f\u52a8 \u63a8\u7406 WebUI \u754c\u9762\uff1f\u7f16\u8f91\u9879\u76ee\u6839\u76ee\u5f55\u4e0b\u7684 <code>API_FLAGS.txt</code>, \u524d\u4e09\u884c\u4fee\u6539\u6210\u5982\u4e0b\u683c\u5f0f: <pre><code>--infer\n# --api\n# --listen ...\n...\n</code></pre></p> <p>\u53ef\u9009</p> <p>\u60f3\u542f\u52a8 API \u670d\u52a1\u5668\uff1f\u7f16\u8f91\u9879\u76ee\u6839\u76ee\u5f55\u4e0b\u7684 <code>API_FLAGS.txt</code>, \u524d\u4e09\u884c\u4fee\u6539\u6210\u5982\u4e0b\u683c\u5f0f: <pre><code># --infer\n--api\n--listen ...\n...\n</code></pre></p> <p>\u53ef\u9009</p> <p>\u53cc\u51fb <code>run_cmd.bat</code> \u8fdb\u5165\u672c\u9879\u76ee\u7684 conda/python \u547d\u4ee4\u884c\u73af\u5883</p>"},{"location":"zh/#linux","title":"Linux \u914d\u7f6e","text":"<pre><code># \u521b\u5efa\u4e00\u4e2a python 3.10 \u865a\u62df\u73af\u5883, \u4f60\u4e5f\u53ef\u4ee5\u7528 virtualenv\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# \u5b89\u88c5 pytorch\npip3 install torch torchvision torchaudio\n\n# \u5b89\u88c5 fish-speech\npip3 install -e .[stable]\n\n# (Ubuntu / Debian \u7528\u6237) \u5b89\u88c5 sox\napt install libsox-dev\n</code></pre>"},{"location":"zh/#docker","title":"Docker \u914d\u7f6e","text":"<ol> <li> <p>\u5b89\u88c5 NVIDIA Container Toolkit\uff1a</p> <p>Docker \u5982\u679c\u60f3\u4f7f\u7528 GPU \u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u548c\u63a8\u7406\uff0c\u9700\u8981\u5b89\u88c5 NVIDIA Container Toolkit \uff1a</p> <p>\u5bf9\u4e8e Ubuntu \u7528\u6237\uff1a</p> <pre><code># \u6dfb\u52a0\u8fdc\u7a0b\u4ed3\u5e93\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n    &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n        sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n# \u5b89\u88c5 nvidia-container-toolkit\nsudo apt-get update\nsudo apt-get install -y nvidia-container-toolkit\n# \u91cd\u542f Docker \u670d\u52a1\nsudo systemctl restart docker\n</code></pre> <p>\u5bf9\u4e8e\u4f7f\u7528\u5176\u4ed6 Linux \u53d1\u884c\u7248\u7684\u7528\u6237\uff0c\u5b89\u88c5\u6307\u5357\u8bf7\u53c2\u8003\uff1aNVIDIA Container Toolkit Install-guide\u3002</p> <p>\u6ce8\uff1a\u5bf9\u4e8e\u4e2d\u56fd\u5927\u9646\u7684\u7528\u6237\uff0c\u60a8\u53ef\u80fd\u9700\u8981\u4f7f\u7528\u4ee3\u7406\u6765\u5b8c\u6210\u76f8\u5173\u5de5\u5177\u7684\u5b89\u88c5\u3002</p> </li> <li> <p>\u62c9\u53d6\u5e76\u8fd0\u884c fish-speech \u955c\u50cf</p> <pre><code># \u62c9\u53d6\u955c\u50cf\ndocker pull lengyue233/fish-speech\n# \u8fd0\u884c\u955c\u50cf\ndocker run -it \\\n    --name fish-speech \\\n    --gpus all \\\n    -p 7860:7860 \\\n    lengyue233/fish-speech \\\n    zsh\n# \u5982\u679c\u9700\u8981\u4f7f\u7528\u5176\u4ed6\u7aef\u53e3\uff0c\u8bf7\u4fee\u6539 -p \u53c2\u6570\u4e3a YourPort:7860\n</code></pre> </li> <li> <p>\u4e0b\u8f7d\u6a21\u578b\u4f9d\u8d56</p> <p>\u786e\u4fdd\u60a8\u5728 docker \u5bb9\u5668\u5185\u7684\u7ec8\u7aef\uff0c\u7136\u540e\u518d\u4ece\u6211\u4eec\u7684 huggingface \u4ed3\u5e93\u4e0b\u8f7d\u6240\u9700\u7684 <code>vqgan</code> \u548c <code>llama</code> \u6a21\u578b\u3002</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u5bf9\u4e8e\u4e2d\u56fd\u5927\u9646\u7528\u6237\uff0c\u53ef\u4ee5\u901a\u8fc7\u955c\u50cf\u7ad9\u4e0b\u8f7d\u3002</p> <pre><code>HF_ENDPOINT=https://hf-mirror.com huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> </li> <li> <p>\u914d\u7f6e\u73af\u5883\u53d8\u91cf\uff0c\u8bbf\u95ee WebUI</p> <p>\u5728 docker \u5bb9\u5668\u5185\u7684\u7ec8\u7aef\uff0c\u8f93\u5165 <code>export GRADIO_SERVER_NAME=\"0.0.0.0\"</code> \uff0c\u4ece\u800c\u8ba9\u5916\u90e8\u53ef\u4ee5\u8bbf\u95ee docker \u5185\u7684 gradio \u670d\u52a1\u3002 \u63a5\u7740\u5728 docker \u5bb9\u5668\u5185\u7684\u7ec8\u7aef\uff0c\u8f93\u5165 <code>python tools/webui.py</code> \u5373\u53ef\u5f00\u542f WebUI \u670d\u52a1\u3002</p> <p>\u5982\u679c\u662f WSL \u6216\u8005\u662f MacOS \uff0c\u8bbf\u95ee http://localhost:7860 \u5373\u53ef\u6253\u5f00 WebUI \u754c\u9762\u3002</p> <p>\u5982\u679c\u662f\u90e8\u7f72\u5728\u670d\u52a1\u5668\u4e0a\uff0c\u66f4\u6362 localhost \u4e3a\u60a8\u7684\u670d\u52a1\u5668 ip \u5373\u53ef\u3002</p> </li> </ol>"},{"location":"zh/#_3","title":"\u66f4\u65b0\u65e5\u5fd7","text":"<ul> <li>2024/09/10: \u66f4\u65b0\u4e86 Fish-Speech \u5230 1.4, \u589e\u52a0\u4e86\u6570\u636e\u96c6\u5927\u5c0f\uff0c quantizer n_groups 4 -&gt; 8.</li> <li>2024/07/02: \u66f4\u65b0\u4e86 Fish-Speech \u5230 1.2 \u7248\u672c\uff0c\u79fb\u9664 VITS Decoder\uff0c\u540c\u65f6\u6781\u5927\u5e45\u5ea6\u63d0\u5347 zero-shot \u80fd\u529b.</li> <li>2024/05/10: \u66f4\u65b0\u4e86 Fish-Speech \u5230 1.1 \u7248\u672c\uff0c\u5f15\u5165\u4e86 VITS Decoder \u6765\u964d\u4f4e\u53e3\u80e1\u548c\u63d0\u9ad8\u97f3\u8272\u76f8\u4f3c\u5ea6.</li> <li>2024/04/22: \u5b8c\u6210\u4e86 Fish-Speech 1.0 \u7248\u672c, \u5927\u5e45\u4fee\u6539\u4e86 VQGAN \u548c LLAMA \u6a21\u578b.</li> <li>2023/12/28: \u6dfb\u52a0\u4e86 <code>lora</code> \u5fae\u8c03\u652f\u6301.</li> <li>2023/12/27: \u6dfb\u52a0\u4e86 <code>gradient checkpointing</code>, <code>causual sampling</code> \u548c <code>flash-attn</code> \u652f\u6301.</li> <li>2023/12/19: \u66f4\u65b0\u4e86 Webui \u548c HTTP API.</li> <li>2023/12/18: \u66f4\u65b0\u4e86\u5fae\u8c03\u6587\u6863\u548c\u76f8\u5173\u4f8b\u5b50.</li> <li>2023/12/17: \u66f4\u65b0\u4e86 <code>text2semantic</code> \u6a21\u578b, \u652f\u6301\u65e0\u97f3\u7d20\u6a21\u5f0f.</li> <li>2023/12/13: \u6d4b\u8bd5\u7248\u53d1\u5e03, \u5305\u542b VQGAN \u6a21\u578b\u548c\u4e00\u4e2a\u57fa\u4e8e LLAMA \u7684\u8bed\u8a00\u6a21\u578b (\u53ea\u652f\u6301\u97f3\u7d20).</li> </ul>"},{"location":"zh/#_4","title":"\u81f4\u8c22","text":"<ul> <li>VITS2 (daniilrobnikov)</li> <li>Bert-VITS2</li> <li>GPT VITS</li> <li>MQTTS</li> <li>GPT Fast</li> <li>Transformers</li> <li>GPT-SoVITS</li> </ul>"},{"location":"zh/finetune/","title":"\u5fae\u8c03","text":"<p>\u663e\u7136, \u5f53\u4f60\u6253\u5f00\u8fd9\u4e2a\u9875\u9762\u7684\u65f6\u5019, \u4f60\u5df2\u7ecf\u5bf9\u9884\u8bad\u7ec3\u6a21\u578b zero-shot \u7684\u6548\u679c\u4e0d\u7b97\u6ee1\u610f. \u4f60\u60f3\u8981\u5fae\u8c03\u4e00\u4e2a\u6a21\u578b, \u4f7f\u5f97\u5b83\u5728\u4f60\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u66f4\u597d.  </p> <p>\u5728\u76ee\u524d\u7248\u672c\uff0c\u4f60\u53ea\u9700\u8981\u5fae\u8c03'LLAMA'\u90e8\u5206\u5373\u53ef.</p>"},{"location":"zh/finetune/#llama","title":"LLAMA \u5fae\u8c03","text":""},{"location":"zh/finetune/#1","title":"1. \u51c6\u5907\u6570\u636e\u96c6","text":"<pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u2514\u2500\u2500 30.1-32.71.mp3\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u2514\u2500\u2500 38.79-40.85.mp3\n</code></pre> <p>\u4f60\u9700\u8981\u5c06\u6570\u636e\u96c6\u8f6c\u4e3a\u4ee5\u4e0a\u683c\u5f0f, \u5e76\u653e\u5230 <code>data</code> \u4e0b, \u97f3\u9891\u540e\u7f00\u53ef\u4ee5\u4e3a <code>.mp3</code>, <code>.wav</code> \u6216 <code>.flac</code>, \u6807\u6ce8\u6587\u4ef6\u540e\u7f00\u5efa\u8bae\u4e3a <code>.lab</code>.</p> <p>Warning</p> <p>\u5efa\u8bae\u5148\u5bf9\u6570\u636e\u96c6\u8fdb\u884c\u54cd\u5ea6\u5339\u914d, \u4f60\u53ef\u4ee5\u4f7f\u7528 fish-audio-preprocess \u6765\u5b8c\u6210\u8fd9\u4e00\u6b65\u9aa4.  <pre><code>fap loudness-norm data-raw data --clean\n</code></pre></p>"},{"location":"zh/finetune/#2-token","title":"2. \u6279\u91cf\u63d0\u53d6\u8bed\u4e49 token","text":"<p>\u786e\u4fdd\u4f60\u5df2\u7ecf\u4e0b\u8f7d\u4e86 vqgan \u6743\u91cd, \u5982\u679c\u6ca1\u6709, \u8bf7\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4:</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u5bf9\u4e8e\u4e2d\u56fd\u5927\u9646\u7528\u6237, \u53ef\u4f7f\u7528 mirror \u4e0b\u8f7d.</p> <pre><code>HF_ENDPOINT=https://hf-mirror.com huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u968f\u540e\u53ef\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u6765\u63d0\u53d6\u8bed\u4e49 token:</p> <pre><code>python tools/vqgan/extract_vq.py data \\\n    --num-workers 1 --batch-size 16 \\\n    --config-name \"firefly_gan_vq\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>Note</p> <p>\u4f60\u53ef\u4ee5\u8c03\u6574 <code>--num-workers</code> \u548c <code>--batch-size</code> \u6765\u63d0\u9ad8\u63d0\u53d6\u901f\u5ea6, \u4f46\u662f\u8bf7\u6ce8\u610f\u4e0d\u8981\u8d85\u8fc7\u4f60\u7684\u663e\u5b58\u9650\u5236.  </p> <p>\u8be5\u547d\u4ee4\u4f1a\u5728 <code>data</code> \u76ee\u5f55\u4e0b\u521b\u5efa <code>.npy</code> \u6587\u4ef6, \u5982\u4e0b\u6240\u793a:</p> <pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 21.15-26.44.npy\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.npy\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u251c\u2500\u2500 30.1-32.71.mp3\n\u2502   \u2514\u2500\u2500 30.1-32.71.npy\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u251c\u2500\u2500 38.79-40.85.mp3\n    \u2514\u2500\u2500 38.79-40.85.npy\n</code></pre>"},{"location":"zh/finetune/#3-protobuf","title":"3. \u6253\u5305\u6570\u636e\u96c6\u4e3a protobuf","text":"<pre><code>python tools/llama/build_dataset.py \\\n    --input \"data\" \\\n    --output \"data/protos\" \\\n    --text-extension .lab \\\n    --num-workers 16\n</code></pre> <p>\u547d\u4ee4\u6267\u884c\u5b8c\u6bd5\u540e, \u4f60\u5e94\u8be5\u80fd\u5728 <code>data</code> \u76ee\u5f55\u4e0b\u770b\u5230 <code>protos</code> \u6587\u4ef6.</p>"},{"location":"zh/finetune/#4-lora","title":"4. \u6700\u540e, \u4f7f\u7528 LoRA \u8fdb\u884c\u5fae\u8c03","text":"<p>\u540c\u6837\u7684, \u8bf7\u786e\u4fdd\u4f60\u5df2\u7ecf\u4e0b\u8f7d\u4e86 <code>LLAMA</code> \u6743\u91cd, \u5982\u679c\u6ca1\u6709, \u8bf7\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4:</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u5bf9\u4e8e\u4e2d\u56fd\u5927\u9646\u7528\u6237, \u53ef\u4f7f\u7528 mirror \u4e0b\u8f7d.</p> <pre><code>HF_ENDPOINT=https://hf-mirror.com huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u6700\u540e, \u4f60\u53ef\u4ee5\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u6765\u542f\u52a8\u5fae\u8c03:</p> <pre><code>python fish_speech/train.py --config-name text2semantic_finetune \\\n    project=$project \\\n    +lora@model.model.lora_config=r_8_alpha_16\n</code></pre> <p>Note</p> <p>\u4f60\u53ef\u4ee5\u901a\u8fc7\u4fee\u6539 <code>fish_speech/configs/text2semantic_finetune.yaml</code> \u6765\u4fee\u6539\u8bad\u7ec3\u53c2\u6570\u5982 <code>batch_size</code>, <code>gradient_accumulation_steps</code> \u7b49, \u6765\u9002\u5e94\u4f60\u7684\u663e\u5b58.</p> <p>Note</p> <p>\u5bf9\u4e8e Windows \u7528\u6237, \u4f60\u53ef\u4ee5\u4f7f\u7528 <code>trainer.strategy.process_group_backend=gloo</code> \u6765\u907f\u514d <code>nccl</code> \u7684\u95ee\u9898.</p> <p>\u8bad\u7ec3\u7ed3\u675f\u540e, \u4f60\u53ef\u4ee5\u53c2\u8003 \u63a8\u7406 \u90e8\u5206, \u5e76\u643a\u5e26 <code>--speaker SPK1</code> \u53c2\u6570\u6765\u6d4b\u8bd5\u4f60\u7684\u6a21\u578b.</p> <p>Info</p> <p>\u9ed8\u8ba4\u914d\u7f6e\u4e0b, \u57fa\u672c\u53ea\u4f1a\u5b66\u5230\u8bf4\u8bdd\u4eba\u7684\u53d1\u97f3\u65b9\u5f0f, \u800c\u4e0d\u5305\u542b\u97f3\u8272, \u4f60\u4f9d\u7136\u9700\u8981\u4f7f\u7528 prompt \u6765\u4fdd\u8bc1\u97f3\u8272\u7684\u7a33\u5b9a\u6027. \u5982\u679c\u4f60\u60f3\u8981\u5b66\u5230\u97f3\u8272, \u8bf7\u5c06\u8bad\u7ec3\u6b65\u6570\u8c03\u5927, \u4f46\u8fd9\u6709\u53ef\u80fd\u4f1a\u5bfc\u81f4\u8fc7\u62df\u5408. </p> <p>\u8bad\u7ec3\u5b8c\u6210\u540e, \u4f60\u9700\u8981\u5148\u5c06 loRA \u7684\u6743\u91cd\u8f6c\u4e3a\u666e\u901a\u6743\u91cd, \u7136\u540e\u518d\u8fdb\u884c\u63a8\u7406.</p> <pre><code>python tools/llama/merge_lora.py \\\n    --lora-config r_8_alpha_16 \\\n    --base-weight checkpoints/fish-speech-1.4 \\\n    --lora-weight results/$project/checkpoints/step_000000010.ckpt \\\n    --output checkpoints/fish-speech-1.4-yth-lora/\n</code></pre> <p>Note</p> <p>\u4f60\u4e5f\u53ef\u4ee5\u5c1d\u8bd5\u5176\u4ed6\u7684 checkpoint, \u6211\u4eec\u5efa\u8bae\u4f60\u4f7f\u7528\u6700\u65e9\u7684\u6ee1\u8db3\u4f60\u8981\u6c42\u7684 checkpoint, \u4ed6\u4eec\u901a\u5e38\u5728 OOD \u4e0a\u8868\u73b0\u66f4\u597d.</p>"},{"location":"zh/inference/","title":"\u63a8\u7406","text":"<p>\u63a8\u7406\u652f\u6301\u547d\u4ee4\u884c, http api, \u4ee5\u53ca webui \u4e09\u79cd\u65b9\u5f0f.</p> <p>Note</p> <p>\u603b\u7684\u6765\u8bf4, \u63a8\u7406\u5206\u4e3a\u51e0\u4e2a\u90e8\u5206:</p> <ol> <li>\u7ed9\u5b9a\u4e00\u6bb5 ~10 \u79d2\u7684\u8bed\u97f3, \u5c06\u5b83\u7528 VQGAN \u7f16\u7801.</li> <li>\u5c06\u7f16\u7801\u540e\u7684\u8bed\u4e49 token \u548c\u5bf9\u5e94\u6587\u672c\u8f93\u5165\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4f8b\u5b50.</li> <li>\u7ed9\u5b9a\u4e00\u6bb5\u65b0\u6587\u672c, \u8ba9\u6a21\u578b\u751f\u6210\u5bf9\u5e94\u7684\u8bed\u4e49 token.</li> <li>\u5c06\u751f\u6210\u7684\u8bed\u4e49 token \u8f93\u5165 VQGAN \u89e3\u7801, \u751f\u6210\u5bf9\u5e94\u7684\u8bed\u97f3.</li> </ol>"},{"location":"zh/inference/#_2","title":"\u547d\u4ee4\u884c\u63a8\u7406","text":"<p>\u4ece\u6211\u4eec\u7684 huggingface \u4ed3\u5e93\u4e0b\u8f7d\u6240\u9700\u7684 <code>vqgan</code> \u548c <code>llama</code> \u6a21\u578b\u3002</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u5bf9\u4e8e\u4e2d\u56fd\u5927\u9646\u7528\u6237\uff0c\u53ef\u4f7f\u7528 mirror \u4e0b\u8f7d\u3002</p> <pre><code>HF_ENDPOINT=https://hf-mirror.com huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre>"},{"location":"zh/inference/#1-prompt","title":"1. \u4ece\u8bed\u97f3\u751f\u6210 prompt:","text":"<p>Note</p> <p>\u5982\u679c\u4f60\u6253\u7b97\u8ba9\u6a21\u578b\u968f\u673a\u9009\u62e9\u97f3\u8272, \u4f60\u53ef\u4ee5\u8df3\u8fc7\u8fd9\u4e00\u6b65.</p> <pre><code>python tools/vqgan/inference.py \\\n    -i \"paimon.wav\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>\u4f60\u5e94\u8be5\u80fd\u5f97\u5230\u4e00\u4e2a <code>fake.npy</code> \u6587\u4ef6.</p>"},{"location":"zh/inference/#2-token","title":"2. \u4ece\u6587\u672c\u751f\u6210\u8bed\u4e49 token:","text":"<pre><code>python tools/llama/generate.py \\\n    --text \"\u8981\u8f6c\u6362\u7684\u6587\u672c\" \\\n    --prompt-text \"\u4f60\u7684\u53c2\u8003\u6587\u672c\" \\\n    --prompt-tokens \"fake.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --num-samples 2 \\\n    --compile\n</code></pre> <p>\u8be5\u547d\u4ee4\u4f1a\u5728\u5de5\u4f5c\u76ee\u5f55\u4e0b\u521b\u5efa <code>codes_N</code> \u6587\u4ef6, \u5176\u4e2d N \u662f\u4ece 0 \u5f00\u59cb\u7684\u6574\u6570.</p> <p>Note</p> <p>\u60a8\u53ef\u80fd\u5e0c\u671b\u4f7f\u7528 <code>--compile</code> \u6765\u878d\u5408 cuda \u5185\u6838\u4ee5\u5b9e\u73b0\u66f4\u5feb\u7684\u63a8\u7406 (~30 \u4e2a token/\u79d2 -&gt; ~500 \u4e2a token/\u79d2). \u5bf9\u5e94\u7684, \u5982\u679c\u4f60\u4e0d\u6253\u7b97\u4f7f\u7528\u52a0\u901f, \u4f60\u53ef\u4ee5\u6ce8\u91ca\u6389 <code>--compile</code> \u53c2\u6570.</p> <p>Info</p> <p>\u5bf9\u4e8e\u4e0d\u652f\u6301 bf16 \u7684 GPU, \u4f60\u53ef\u80fd\u9700\u8981\u4f7f\u7528 <code>--half</code> \u53c2\u6570.</p>"},{"location":"zh/inference/#3-token","title":"3. \u4ece\u8bed\u4e49 token \u751f\u6210\u4eba\u58f0:","text":""},{"location":"zh/inference/#vqgan","title":"VQGAN \u89e3\u7801","text":"<pre><code>python tools/vqgan/inference.py \\\n    -i \"codes_0.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre>"},{"location":"zh/inference/#http-api","title":"HTTP API \u63a8\u7406","text":"<p>\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u6765\u542f\u52a8 HTTP \u670d\u52a1:</p> <p><pre><code>python -m tools.api \\\n    --listen 0.0.0.0:8080 \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> \u5982\u679c\u4f60\u60f3\u8981\u52a0\u901f\u63a8\u7406\uff0c\u53ef\u4ee5\u52a0\u4e0a<code>--compile</code>\u53c2\u6570\u3002</p> <p>\u63a8\u8350\u4e2d\u56fd\u5927\u9646\u7528\u6237\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u6765\u542f\u52a8 HTTP \u670d\u52a1: <pre><code>HF_ENDPOINT=https://hf-mirror.com python -m ...(\u540c\u4e0a)\n</code></pre></p> <p>\u968f\u540e, \u4f60\u53ef\u4ee5\u5728 <code>http://127.0.0.1:8080/</code> \u4e2d\u67e5\u770b\u5e76\u6d4b\u8bd5 API.</p> <p>\u4e0b\u9762\u662f\u4f7f\u7528<code>tools/post_api.py</code>\u53d1\u9001\u8bf7\u6c42\u7684\u793a\u4f8b\u3002</p> <pre><code>python -m tools.post_api \\\n    --text \"\u8981\u8f93\u5165\u7684\u6587\u672c\" \\\n    --reference_audio \"\u53c2\u8003\u97f3\u9891\u8def\u5f84\" \\\n    --reference_text \"\u53c2\u8003\u97f3\u9891\u7684\u6587\u672c\u5185\u5bb9\" \\\n    --streaming True\n</code></pre> <p>\u4e0a\u9762\u7684\u547d\u4ee4\u8868\u793a\u6309\u7167\u53c2\u8003\u97f3\u9891\u7684\u4fe1\u606f\uff0c\u5408\u6210\u6240\u9700\u7684\u97f3\u9891\u5e76\u6d41\u5f0f\u8fd4\u56de.</p> <p>\u4e0b\u9762\u7684\u793a\u4f8b\u5c55\u793a\u4e86\uff0c \u53ef\u4ee5\u4e00\u6b21\u4f7f\u7528\u591a\u4e2a <code>\u53c2\u8003\u97f3\u9891\u8def\u5f84</code> \u548c <code>\u53c2\u8003\u97f3\u9891\u7684\u6587\u672c\u5185\u5bb9</code>\u3002\u5728\u547d\u4ee4\u91cc\u7528\u7a7a\u683c\u9694\u5f00\u5373\u53ef\u3002 </p> <pre><code>python -m tools.post_api \\\n    --text \"\u8981\u8f93\u5165\u7684\u6587\u672c\" \\\n    --reference_audio \"\u53c2\u8003\u97f3\u9891\u8def\u5f841\" \"\u53c2\u8003\u97f3\u9891\u8def\u5f842\" \\\n    --reference_text \"\u53c2\u8003\u97f3\u9891\u7684\u6587\u672c\u5185\u5bb91\" \"\u53c2\u8003\u97f3\u9891\u7684\u6587\u672c\u5185\u5bb92\"\\\n    --streaming False \\\n    --output \"generated\" \\\n    --format \"mp3\"\n</code></pre> <p>\u4e0a\u9762\u7684\u547d\u4ee4\u8868\u793a\u6309\u7167\u591a\u4e2a\u53c2\u8003\u97f3\u9891\u7684\u4fe1\u606f\uff0c\u5408\u6210\u6240\u9700\u7684<code>MP3</code>\u683c\u5f0f\u97f3\u9891\uff0c\u5e76\u4fdd\u5b58\u4e3a\u5f53\u524d\u76ee\u5f55\u7684<code>generated.mp3</code>\u6587\u4ef6\u3002</p>"},{"location":"zh/inference/#gui","title":"GUI \u63a8\u7406","text":"<p>\u4e0b\u8f7d\u5ba2\u6237\u7aef</p>"},{"location":"zh/inference/#webui","title":"WebUI \u63a8\u7406","text":"<p>\u4f60\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u6765\u542f\u52a8 WebUI:</p> <pre><code>python -m tools.webui \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>Note</p> <p>\u4f60\u53ef\u4ee5\u4f7f\u7528 Gradio \u73af\u5883\u53d8\u91cf, \u5982 <code>GRADIO_SHARE</code>, <code>GRADIO_SERVER_PORT</code>, <code>GRADIO_SERVER_NAME</code> \u6765\u914d\u7f6e WebUI.</p> <p>\u795d\u5927\u5bb6\u73a9\u5f97\u5f00\u5fc3!</p>"},{"location":"zh/samples/","title":"\u4f8b\u5b50","text":"<p>v1.2 \u7684\u6837\u672c\u53ef\u4ee5\u5728 Bilibili \u89c2\u770b\u3002</p> <p>\u4ee5\u4e0b\u6837\u672c\u6765\u81ea v1.1 \u7248\u672c\u7684\u6a21\u578b\u3002</p>"},{"location":"zh/samples/#1","title":"\u4e2d\u6587\u53e5\u5b50 1","text":"<pre><code>\u4eba\u95f4\u706f\u706b\u5012\u6620\u6e56\u4e2d\uff0c\u5979\u7684\u6e34\u671b\u8ba9\u9759\u6c34\u6cdb\u8d77\u6d9f\u6f2a\u3002\u82e5\u4ee3\u4ef7\u53ea\u662f\u5b64\u72ec\uff0c\u90a3\u5c31\u8ba9\u8fd9\u4efd\u613f\u671b\u8086\u610f\u6d41\u6dcc\u3002\n\u6d41\u5165\u5979\u6240\u6ce8\u89c6\u7684\u4e16\u95f4\uff0c\u4e5f\u6d41\u5165\u5979\u5982\u6e56\u6c34\u822c\u6f84\u6f88\u7684\u76ee\u5149\u3002\n</code></pre> \u8bf4\u8bdd\u4eba \u8f93\u5165\u97f3\u9891 \u5408\u6210\u97f3\u9891 \u7eb3\u897f\u59b2 (\u539f\u795e) \u949f\u79bb (\u539f\u795e) \u8299\u5b81\u5a1c (\u539f\u795e) \u968f\u673a\u8bf4\u8bdd\u4eba 1  -  \u968f\u673a\u8bf4\u8bdd\u4eba 2  -"},{"location":"zh/samples/#2","title":"\u4e2d\u6587\u53e5\u5b50 2","text":"<pre><code>\u4f60\u4eec\u8fd9\u4e2a\u662f\u4ec0\u4e48\u7fa4\u554a\uff0c\u4f60\u4eec\u8fd9\u662f\u5bb3\u4eba\u4e0d\u6d45\u554a\u4f60\u4eec\u8fd9\u4e2a\u7fa4\uff01\u8c01\u662f\u7fa4\u4e3b\uff0c\u51fa\u6765\uff01\u771f\u7684\u592a\u8fc7\u5206\u4e86\u3002\u4f60\u4eec\u641e\u8fd9\u4e2a\u7fa4\u5e72\u4ec0\u4e48\uff1f\n\u6211\u513f\u5b50\u6bcf\u4e00\u79d1\u7684\u6210\u7ee9\u90fd\u4e0d\u8fc7\u90a3\u4e2a\u5e73\u5747\u5206\u5450\uff0c\u4ed6\u73b0\u5728\u521d\u4e8c\uff0c\u4f60\u53eb\u6211\u513f\u5b50\u600e\u4e48\u529e\u554a\uff1f\u4ed6\u73b0\u5728\u8fd8\u4e0d\u5230\u9ad8\u4e2d\u554a\uff1f\n\u4f60\u4eec\u5bb3\u6b7b\u6211\u513f\u5b50\u4e86\uff01\u5feb\u70b9\u51fa\u6765\u4f60\u8fd9\u4e2a\u7fa4\u4e3b\uff01\u518d\u8fd9\u6837\u6211\u53bb\u62a5\u8b66\u4e86\u554a\uff01\u6211\u8ddf\u4f60\u4eec\u8bf4\u4f60\u4eec\u8fd9\u4e00\u5e2e\u4eba\u554a\uff0c\u4e00\u5929\u5230\u665a\u554a\uff0c\n\u641e\u8fd9\u4e9b\u4ec0\u4e48\u6e38\u620f\u554a\uff0c\u52a8\u6f2b\u554a\uff0c\u4f1a\u5bb3\u6b7b\u4f60\u4eec\u7684\uff0c\u4f60\u4eec\u6ca1\u6709\u524d\u9014\u6211\u8ddf\u4f60\u8bf4\u3002\u4f60\u4eec\u8fd9\u4e5d\u767e\u591a\u4e2a\u4eba\uff0c\u597d\u597d\u5b66\u4e60\u4e0d\u597d\u5417\uff1f\n\u4e00\u5929\u5230\u665a\u5728\u4e0a\u7f51\u3002\u6709\u4ec0\u4e48\u610f\u601d\u554a\uff1f\u9ebb\u70e6\u4f60\u91cd\u89c6\u4e00\u4e0b\u4f60\u4eec\u7684\u751f\u6d3b\u7684\u76ee\u6807\u554a\uff1f\u6709\u4e00\u70b9\u5b66\u4e60\u76ee\u6807\u884c\u4e0d\u884c\uff1f\u4e00\u5929\u5230\u665a\u4e0a\u7f51\u662f\u4e0d\u662f\u4eba\u554a\uff1f\n</code></pre> \u8bf4\u8bdd\u4eba \u8f93\u5165\u97f3\u9891 \u5408\u6210\u97f3\u9891 \u7eb3\u897f\u59b2 (\u539f\u795e) \u968f\u673a\u8bf4\u8bdd\u4eba  -"},{"location":"zh/samples/#3","title":"\u4e2d\u6587\u53e5\u5b50 3","text":"<pre><code>\u5927\u5bb6\u597d\uff0c\u6211\u662f Fish Audio \u5f00\u53d1\u7684\u5f00\u6e90\u6587\u672c\u8f6c\u8bed\u97f3\u6a21\u578b\u3002\u7ecf\u8fc7\u5341\u4e94\u4e07\u5c0f\u65f6\u7684\u6570\u636e\u8bad\u7ec3\uff0c\n\u6211\u5df2\u7ecf\u80fd\u591f\u719f\u7ec3\u638c\u63e1\u4e2d\u6587\u3001\u65e5\u8bed\u548c\u82f1\u8bed\uff0c\u6211\u7684\u8bed\u8a00\u5904\u7406\u80fd\u529b\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0c\u58f0\u97f3\u8868\u73b0\u5f62\u5f0f\u4e30\u5bcc\u591a\u53d8\u3002\n\u4f5c\u4e3a\u4e00\u4e2a\u4ec5\u6709\u4ebf\u7ea7\u53c2\u6570\u7684\u6a21\u578b\uff0c\u6211\u76f8\u4fe1\u793e\u533a\u6210\u5458\u80fd\u591f\u5728\u4e2a\u4eba\u8bbe\u5907\u4e0a\u8f7b\u677e\u8fd0\u884c\u548c\u5fae\u8c03\uff0c\u8ba9\u6211\u6210\u4e3a\u60a8\u7684\u79c1\u4eba\u8bed\u97f3\u52a9\u624b\u3002\n</code></pre> \u8bf4\u8bdd\u4eba \u8f93\u5165\u97f3\u9891 \u5408\u6210\u97f3\u9891 \u968f\u673a\u8bf4\u8bdd\u4eba  -"},{"location":"zh/samples/#1_1","title":"\u82f1\u6587\u53e5\u5b50 1","text":"<pre><code>In the realm of advanced technology, the evolution of artificial intelligence stands as a \nmonumental achievement. This dynamic field, constantly pushing the boundaries of what \nmachines can do, has seen rapid growth and innovation. From deciphering complex data \npatterns to driving cars autonomously, AI's applications are vast and diverse.\n</code></pre> \u8bf4\u8bdd\u4eba \u8f93\u5165\u97f3\u9891 \u5408\u6210\u97f3\u9891 \u968f\u673a\u8bf4\u8bdd\u4eba 1  -  \u968f\u673a\u8bf4\u8bdd\u4eba 2  -"},{"location":"zh/samples/#2_1","title":"\u82f1\u6587\u53e5\u5b50 2","text":"<pre><code>Hello everyone, I am an open-source text-to-speech model developed by \nFish Audio. After training with 150,000 hours of data, I have become proficient \nin Chinese, Japanese, and English, and my language processing abilities \nare close to human level. My voice is capable of a wide range of expressions. \nAs a model with only hundreds of millions of parameters, I believe community \nmembers can easily run and fine-tune me on their personal devices, allowing \nme to serve as your personal voice assistant.\n</code></pre> \u8bf4\u8bdd\u4eba \u8f93\u5165\u97f3\u9891 \u5408\u6210\u97f3\u9891 \u968f\u673a\u8bf4\u8bdd\u4eba  -"},{"location":"zh/samples/#1_2","title":"\u65e5\u6587\u53e5\u5b50 1","text":"<pre><code>\u5148\u9032\u6280\u8853\u306e\u9818\u57df\u306b\u304a\u3044\u3066\u3001\u4eba\u5de5\u77e5\u80fd\u306e\u9032\u5316\u306f\u753b\u671f\u7684\u306a\u6210\u679c\u3068\u3057\u3066\u7acb\u3063\u3066\u3044\u307e\u3059\u3002\u5e38\u306b\u6a5f\u68b0\u304c\u3067\u304d\u308b\u3053\u3068\u306e\u9650\u754c\u3092\n\u62bc\u3057\u5e83\u3052\u3066\u3044\u308b\u3053\u306e\u30c0\u30a4\u30ca\u30df\u30c3\u30af\u306a\u5206\u91ce\u306f\u3001\u6025\u901f\u306a\u6210\u9577\u3068\u9769\u65b0\u3092\u898b\u305b\u3066\u3044\u307e\u3059\u3002\u8907\u96d1\u306a\u30c7\u30fc\u30bf\u30d1\u30bf\u30fc\u30f3\u306e\u89e3\u8aad\u304b\n\u3089\u81ea\u52d5\u904b\u8ee2\u8eca\u306e\u64cd\u7e26\u307e\u3067\u3001AI\u306e\u5fdc\u7528\u306f\u5e83\u7bc4\u56f2\u306b\u53ca\u3073\u307e\u3059\u3002\n</code></pre> \u8bf4\u8bdd\u4eba \u8f93\u5165\u97f3\u9891 \u5408\u6210\u97f3\u9891 \u968f\u673a\u8bf4\u8bdd\u4eba 1  -  \u968f\u673a\u8bf4\u8bdd\u4eba 2  -"},{"location":"zh/samples/#2_2","title":"\u65e5\u6587\u53e5\u5b50 2","text":"<pre><code>\u7686\u3055\u3093\u3001\u3053\u3093\u306b\u3061\u306f\u3002\u79c1\u306f\u30d5\u30a3\u30c3\u30b7\u30e5\u30aa\u30fc\u30c7\u30a3\u30aa\u306b\u3088\u3063\u3066\u958b\u767a\u3055\u308c\u305f\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u306e\u30c6\n\u30ad\u30b9\u30c8\u304b\u3089\u97f3\u58f0\u3078\u306e\u5909\u63db\u30e2\u30c7\u30eb\u3067\u3059\u300215\u4e07\u6642\u9593\u306e\u30c7\u30fc\u30bf\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u7d4c\u3066\u3001\n\u4e2d\u56fd\u8a9e\u3001\u65e5\u672c\u8a9e\u3001\u82f1\u8a9e\u3092\u719f\u77e5\u3057\u3066\u304a\u308a\u3001\u8a00\u8a9e\u51e6\u7406\u80fd\u529b\u306f\u4eba\u9593\u306b\u8fd1\u3044\u30ec\u30d9\u30eb\u3067\u3059\u3002\n\u58f0\u306e\u8868\u73fe\u3082\u591a\u5f69\u3067\u8c4a\u304b\u3067\u3059\u3002\u6570\u5104\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6301\u3064\u3053\u306e\u30e2\u30c7\u30eb\u306f\u3001\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\n\u306e\u30e1\u30f3\u30d0\u30fc\u304c\u500b\u4eba\u306e\u30c7\u30d0\u30a4\u30b9\u3067\u7c21\u5358\u306b\u5b9f\u884c\u3057\u3001\u5fae\u8abf\u6574\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3068\n\u4fe1\u3058\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u79c1\u3092\u500b\u4eba\u306e\u97f3\u58f0\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3068\u3057\u3066\u6d3b\u7528\u3067\u304d\u307e\u3059\u3002\n</code></pre> \u8bf4\u8bdd\u4eba \u8f93\u5165\u97f3\u9891 \u5408\u6210\u97f3\u9891 \u968f\u673a\u8bf4\u8bdd\u4eba  -"},{"location":"ja/","title":"Fish Speech \u306e\u7d39\u4ecb","text":"<p>Warning</p> <p>\u79c1\u305f\u3061\u306f\u3001\u30b3\u30fc\u30c9\u30d9\u30fc\u30b9\u306e\u9055\u6cd5\u306a\u4f7f\u7528\u306b\u3064\u3044\u3066\u4e00\u5207\u306e\u8cac\u4efb\u3092\u8ca0\u3044\u307e\u305b\u3093\u3002\u304a\u4f4f\u307e\u3044\u306e\u5730\u57df\u306e DMCA\uff08\u30c7\u30b8\u30bf\u30eb\u30df\u30ec\u30cb\u30a2\u30e0\u8457\u4f5c\u6a29\u6cd5\uff09\u304a\u3088\u3073\u305d\u306e\u4ed6\u306e\u95a2\u9023\u6cd5\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002  \u3053\u306e\u30b3\u30fc\u30c9\u30d9\u30fc\u30b9\u3068\u30e2\u30c7\u30eb\u306f\u3001CC-BY-NC-SA-4.0 \u30e9\u30a4\u30bb\u30f3\u30b9\u4e0b\u3067\u30ea\u30ea\u30fc\u30b9\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p> <p> </p>"},{"location":"ja/#_1","title":"\u8981\u4ef6","text":"<ul> <li>GPU \u30e1\u30e2\u30ea: 4GB\uff08\u63a8\u8ad6\u7528\uff09\u30018GB\uff08\u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u7528\uff09</li> <li>\u30b7\u30b9\u30c6\u30e0: Linux\u3001Windows</li> </ul>"},{"location":"ja/#windows","title":"Windows \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7","text":"<p>Window \u306b\u3066\u958b\u767a\u3092\u884c\u3063\u3066\u3044\u308b\u65b9\u3078: \u672c\u30b3\u30fc\u30c9\u30d9\u30fc\u30b9\u3092\u5b9f\u884c\u3059\u308b\u306e\u306b WSL2 \u307e\u305f\u306f Docker \u3092\u5229\u7528\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</p> <p>\u3042\u307e\u308a\u8a73\u3057\u304f\u306a\u3044\u4eba\u306f\u3001Linux \u74b0\u5883\u306a\u3057\u3067\u30b3\u30fc\u30c9\u30d9\u30fc\u30b9\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u306b\u4ee5\u4e0b\u306e\u624b\u9806\u306b\u5f93\u3063\u3066\u304f\u3060\u3055\u3044\u3002\uff08\u30e2\u30c7\u30eb\u30b3\u30f3\u30d1\u30a4\u30eb\u6a5f\u80fd<code>torch.compile</code>\u3092\u5229\u7528\u3067\u304d\u307e\u3059\u3002\uff09\uff1a</p> <ol> <li>\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u5727\u7e2e\u30d5\u30a1\u30a4\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3001\u5c55\u958b</li> <li><code>install_env.bat</code>\u3092\u958b\u3044\u3066\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u74b0\u5883\u3092\u6574\u3048\u307e\u3059\u3002       <ul> <li><code>install_env.bat</code>\u306e<code>USE_MIRROR</code>\u30df\u30e9\u30fc\u30b5\u30a4\u30c8\u3092\u4f7f\u7528\u3059\u308b\u5834\u5408\u3001\u9805\u76ee\u3092\u7de8\u96c6\u3057\u3066\u304f\u3060\u3055\u3044\u3002</li> <li><code>USE_MIRROR=false</code>\u306f\u3001\u6700\u65b0\u306e\u5b89\u5b9a\u7248\u306e<code>torch</code>\u3092\u30aa\u30ea\u30b8\u30ca\u30eb\u30b5\u30a4\u30c8\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002<code>USE_MIRROR=true</code>\u306f\u3001\u6700\u65b0\u306e<code>torch</code>\u3092\u30df\u30e9\u30fc\u30b5\u30a4\u30c8\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306f<code>true</code>\u3067\u3059\u3002</li> <li><code>install_env.bat</code>\u306e<code>INSTALL_TYPE</code>\u3092\u7de8\u96c6\u3057\u3066\u3001\u30b3\u30f3\u30d1\u30a4\u30eb\u74b0\u5883\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u304b\u3092\u8a2d\u5b9a\u3067\u304d\u307e\u3059\u3002</li> <li><code>INSTALL_TYPE=preview</code>\u306f\u3001\u30b3\u30f3\u30d1\u30a4\u30eb\u74b0\u5883\u4ed8\u304d\u306e\u30d7\u30ec\u30d3\u30e5\u30fc\u7248\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002<code>INSTALL_TYPE=stable</code>\u306f\u3001\u30b3\u30f3\u30d1\u30a4\u30eb\u74b0\u5883\u306a\u3057\u306e\u5b89\u5b9a\u7248\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002</li> </ul> </li> <li>\u30b9\u30c6\u30c3\u30d72\u3067<code>USE_MIRROR=preview</code>\u306e\u5834\u5408\u3001\u30aa\u30d7\u30b7\u30e7\u30f3\u3001\u30b3\u30f3\u30d1\u30a4\u30eb\u30e2\u30c7\u30eb\u74b0\u5883\u3092\u6709\u52b9\u306b\u3059\u308b\u305f\u306b\u4ee5\u4e0b\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u5b9f\u884c\u3057\u3066\u304f\u3060\u3055\u3044\u3002\uff1a       <ol> <li>\u4ee5\u4e0b\u306e\u30ea\u30f3\u30af\u304b\u3089LLVM\u30b3\u30f3\u30d1\u30a4\u30e9\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\uff1a                <ul> <li>LLVM-17.0.6\uff08\u30aa\u30ea\u30b8\u30ca\u30eb\u30b5\u30a4\u30c8\uff09</li> <li>LLVM-17.0.6\uff08\u30df\u30e9\u30fc\u30b5\u30a4\u30c8\uff09</li> <li><code>LLVM-17.0.6-win64.exe</code>\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u5f8c\u3001\u30c0\u30d6\u30eb\u30af\u30ea\u30c3\u30af\u3057\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3001\u9069\u5f53\u306a\u5834\u6240\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u5fc5\u305a<code>Add Path to Current User</code>\u3092\u30c1\u30a7\u30c3\u30af\u3057\u3066\u74b0\u5883\u5909\u6570\u306b\u8ffd\u52a0\u3059\u308b\u3053\u3068\u3067\u3059\u3002</li> <li>\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u5b8c\u4e86\u3057\u305f\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u304f\u3060\u3055\u3044\u3002</li> </ul> </li> <li>Microsoft Visual C++ \u518d\u9812\u5e03\u53ef\u80fd\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3001dll\u306e\u6b20\u843d\u554f\u984c\u3092\u89e3\u6c7a\u3057\u307e\u3059\u3002                <ul> <li>MSVC++ 14.40.33810.0 \u30c0\u30a6\u30f3\u30ed\u30fc\u30c9</li> </ul> </li> <li>Visual Studio Community Edition\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3001MSVC++\u30d3\u30eb\u30c9\u30c4\u30fc\u30eb\u3092\u53d6\u5f97\u3057\u3001LLVM\u306e\u30d8\u30c3\u30c0\u30fc\u30d5\u30a1\u30a4\u30eb\u4f9d\u5b58\u95a2\u4fc2\u3092\u89e3\u6c7a\u3057\u307e\u3059\u3002                <ul> <li>Visual Studio \u30c0\u30a6\u30f3\u30ed\u30fc\u30c9</li> <li>Visual Studio Installer\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u5f8c\u3001Visual Studio Community 2022\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002</li> <li>\u4ee5\u4e0b\u306e\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8\u306e\u3088\u3046\u306b<code>Modify</code>\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3057\u3001<code>Desktop development with C++</code>\u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u30c1\u30a7\u30c3\u30af\u3092\u3064\u3051\u3066\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002</li> <p> </p> </ul> </li> <li>\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb CUDA Toolkit 12</li> </ol> </li> <li><code>start.bat</code>\u3092\u5b9f\u884c\u3057\u3001Fish-Speech\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0/\u63a8\u8ad6\u8a2d\u5b9aWebUI\u3092\u958b\u3044\u3066\u304f\u3060\u3055\u3044\u3002\u3002       <ul> <li>\uff08\u30aa\u30d7\u30b7\u30e7\u30f3\uff09\u76f4\u63a5\u63a8\u8ad6\u30da\u30fc\u30b8\u306b\u884c\u304d\u305f\u3044\u5834\u5408\u306f\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e<code>API_FLAGS.txt</code>\u306e\u6700\u521d\u306e3\u884c\u3092\u6b21\u306e\u3088\u3046\u306b\u5909\u66f4\u3057\u3066\u304f\u3060\u3055\u3044\uff1a                <pre><code>--infer\n# --api\n# --listen ...\n...</code></pre> </li> <li>\uff08\u30aa\u30d7\u30b7\u30e7\u30f3\uff09API\u30b5\u30fc\u30d0\u30fc\u3092\u8d77\u52d5\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e<code>API_FLAGS.txt</code>\u306e\u6700\u521d\u306e3\u884c\u3092\u6b21\u306e\u3088\u3046\u306b\u5909\u66f4\u3057\u3066\u304f\u3060\u3055\u3044\uff1a                <pre><code># --infer\n--api\n--listen ...\n...</code></pre> </li> </ul> </li> <li>\uff08\u30aa\u30d7\u30b7\u30e7\u30f3\uff09<code>run_cmd.bat</code>\u3092\u30c0\u30d6\u30eb\u30af\u30ea\u30c3\u30af\u3057\u3066\u3001\u3053\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u4eee\u60f3\u74b0\u5883\u3092\u6709\u52b9\u5316\u3067\u304d\u307e\u3059\u3002</li> </ol>"},{"location":"ja/#linux","title":"Linux \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7","text":"<pre><code># python 3.10\u306e\u4eee\u60f3\u74b0\u5883\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002virtualenv\u3082\u4f7f\u7528\u3067\u304d\u307e\u3059\u3002\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# pytorch\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\npip3 install torch torchvision torchaudio\n\n# fish-speech\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\npip3 install -e .[stable]\n\n# (Ubuntu / Debian\u30e6\u30fc\u30b6\u30fc) sox\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002\napt install libsox-dev\n</code></pre>"},{"location":"ja/#_2","title":"\u5909\u66f4\u5c65\u6b74","text":"<ul> <li>2024/07/02: Fish-Speech \u3092 Ver.1.2 \u306b\u66f4\u65b0\u3057\u3001VITS \u30c7\u30b3\u30fc\u30c0\u30fc\u3092\u524a\u9664\u3057\u3001\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u80fd\u529b\u3092\u5927\u5e45\u306b\u5f37\u5316\u3057\u307e\u3057\u305f\u3002</li> <li>2024/05/10: Fish-Speech \u3092 Ver.1.1 \u306b\u66f4\u65b0\u3057\u3001VITS \u30c7\u30b3\u30fc\u30c0\u30fc\u3092\u5b9f\u88c5\u3057\u3066 WER \u3092\u6e1b\u5c11\u3055\u305b\u3001\u97f3\u8272\u306e\u985e\u4f3c\u6027\u3092\u5411\u4e0a\u3055\u305b\u307e\u3057\u305f\u3002</li> <li>2024/04/22: Fish-Speech Ver.1.0 \u3092\u5b8c\u6210\u3055\u305b\u3001VQGAN \u304a\u3088\u3073 LLAMA \u30e2\u30c7\u30eb\u3092\u5927\u5e45\u306b\u4fee\u6b63\u3057\u307e\u3057\u305f\u3002</li> <li>2023/12/28: <code>lora</code>\u5fae\u8abf\u6574\u30b5\u30dd\u30fc\u30c8\u3092\u8ffd\u52a0\u3057\u307e\u3057\u305f\u3002</li> <li>2023/12/27: <code>gradient checkpointing</code>\u3001<code>causual sampling</code>\u3001\u304a\u3088\u3073<code>flash-attn</code>\u30b5\u30dd\u30fc\u30c8\u3092\u8ffd\u52a0\u3057\u307e\u3057\u305f\u3002</li> <li>2023/12/19: webui \u304a\u3088\u3073 HTTP API \u3092\u66f4\u65b0\u3057\u307e\u3057\u305f\u3002</li> <li>2023/12/18: \u5fae\u8abf\u6574\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u304a\u3088\u3073\u95a2\u9023\u4f8b\u3092\u66f4\u65b0\u3057\u307e\u3057\u305f\u3002</li> <li>2023/12/17: <code>text2semantic</code>\u30e2\u30c7\u30eb\u3092\u66f4\u65b0\u3057\u3001\u81ea\u7531\u97f3\u7d20\u30e2\u30fc\u30c9\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u307e\u3057\u305f\u3002</li> <li>2023/12/13: \u30d9\u30fc\u30bf\u7248\u3092\u30ea\u30ea\u30fc\u30b9\u3057\u3001VQGAN \u30e2\u30c7\u30eb\u304a\u3088\u3073 LLAMA \u306b\u57fa\u3065\u304f\u8a00\u8a9e\u30e2\u30c7\u30eb\uff08\u97f3\u7d20\u306e\u307f\u30b5\u30dd\u30fc\u30c8\uff09\u3092\u542b\u307f\u307e\u3059\u3002</li> </ul>"},{"location":"ja/#_3","title":"\u8b1d\u8f9e","text":"<ul> <li>VITS2 (daniilrobnikov)</li> <li>Bert-VITS2</li> <li>GPT VITS</li> <li>MQTTS</li> <li>GPT Fast</li> <li>Transformers</li> <li>GPT-SoVITS</li> </ul>"},{"location":"ja/finetune/","title":"\u5fae\u8abf\u6574","text":"<p>\u660e\u3089\u304b\u306b\u3001\u3053\u306e\u30da\u30fc\u30b8\u3092\u958b\u3044\u305f\u3068\u304d\u3001few-shot \u4e8b\u524d\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30e2\u30c7\u30eb\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306b\u6e80\u8db3\u3057\u3066\u3044\u306a\u304b\u3063\u305f\u3053\u3068\u3067\u3057\u3087\u3046\u3002\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u4e0a\u3067\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u5411\u4e0a\u3055\u305b\u308b\u305f\u3081\u306b\u30e2\u30c7\u30eb\u3092\u5fae\u8abf\u6574\u3057\u305f\u3044\u3068\u8003\u3048\u3066\u3044\u307e\u3059\u3002</p> <p>\u73fe\u5728\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3067\u306f\u3001\u300cLLAMA\u300d\u90e8\u5206\u306e\u307f\u3092\u5fae\u8abf\u6574\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002</p>"},{"location":"ja/finetune/#llama","title":"LLAMA\u306e\u5fae\u8abf\u6574","text":""},{"location":"ja/finetune/#1","title":"1. \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u6e96\u5099","text":"<pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u2514\u2500\u2500 30.1-32.71.mp3\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u2514\u2500\u2500 38.79-40.85.mp3\n</code></pre> <p>\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4e0a\u8a18\u306e\u5f62\u5f0f\u306b\u5909\u63db\u3057\u3001\u300cdata\u300d\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u914d\u7f6e\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u97f3\u58f0\u30d5\u30a1\u30a4\u30eb\u306e\u62e1\u5f35\u5b50\u306f\u300c.mp3\u300d\u3001\u300c.wav\u300d\u3001\u307e\u305f\u306f\u300c.flac\u300d\u306b\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u3001\u6ce8\u91c8\u30d5\u30a1\u30a4\u30eb\u306e\u62e1\u5f35\u5b50\u306f\u300c.lab\u300d\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002</p> <p>Warning</p> <p>\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u30e9\u30a6\u30c9\u30cd\u30b9\u6b63\u898f\u5316\u3092\u9069\u7528\u3059\u308b\u3053\u3068\u3092\u304a\u52e7\u3081\u3057\u307e\u3059\u3002\u3053\u308c\u3092\u884c\u3046\u306b\u306f\u3001fish-audio-preprocess \u3092\u4f7f\u7528\u3067\u304d\u307e\u3059\u3002</p> <pre><code>fap loudness-norm data-raw data --clean\n</code></pre>"},{"location":"ja/finetune/#2","title":"2. \u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30c8\u30fc\u30af\u30f3\u306e\u30d0\u30c3\u30c1\u62bd\u51fa","text":"<p>VQGAN\u306e\u91cd\u307f\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u307e\u3060\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u3001\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u6b21\u306b\u3001\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30c8\u30fc\u30af\u30f3\u3092\u62bd\u51fa\u3067\u304d\u307e\u3059\u3002</p> <pre><code>python tools/vqgan/extract_vq.py data \\\n    --num-workers 1 --batch-size 16 \\\n    --config-name \"firefly_gan_vq\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>Note</p> <p><code>--num-workers</code> \u3068 <code>--batch-size</code> \u3092\u8abf\u6574\u3057\u3066\u62bd\u51fa\u901f\u5ea6\u3092\u4e0a\u3052\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u304c\u3001GPU\u30e1\u30e2\u30ea\u306e\u5236\u9650\u3092\u8d85\u3048\u306a\u3044\u3088\u3046\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002 VITS\u5f62\u5f0f\u306e\u5834\u5408\u3001<code>--filelist xxx.list</code> \u3092\u4f7f\u7528\u3057\u3066\u30d5\u30a1\u30a4\u30eb\u30ea\u30b9\u30c8\u3092\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002</p> <p>\u3053\u306e\u30b3\u30de\u30f3\u30c9\u306f\u3001<code>data</code>\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b<code>.npy</code>\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8868\u793a\u3055\u308c\u307e\u3059\u3002</p> <pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 21.15-26.44.npy\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.npy\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u251c\u2500\u2500 30.1-32.71.mp3\n\u2502   \u2514\u2500\u2500 30.1-32.71.npy\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u251c\u2500\u2500 38.79-40.85.mp3\n    \u2514\u2500\u2500 38.79-40.85.npy\n</code></pre>"},{"location":"ja/finetune/#3-protobuf","title":"3. \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092protobuf\u306b\u30d1\u30c3\u30af\u3059\u308b","text":"<pre><code>python tools/llama/build_dataset.py \\\n    --input \"data\" \\\n    --output \"data/protos\" \\\n    --text-extension .lab \\\n    --num-workers 16\n</code></pre> <p>\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\u304c\u5b8c\u4e86\u3059\u308b\u3068\u3001<code>data</code>\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b<code>quantized-dataset-ft.protos</code>\u30d5\u30a1\u30a4\u30eb\u304c\u8868\u793a\u3055\u308c\u307e\u3059\u3002</p>"},{"location":"ja/finetune/#4-lora","title":"4. \u6700\u5f8c\u306b\u3001LoRA\u3092\u4f7f\u7528\u3057\u3066\u5fae\u8abf\u6574\u3059\u308b","text":"<p>\u540c\u69d8\u306b\u3001<code>LLAMA</code>\u306e\u91cd\u307f\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u307e\u3060\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u3001\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>\u6700\u5f8c\u306b\u3001\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u5fae\u8abf\u6574\u3092\u958b\u59cb\u3067\u304d\u307e\u3059\u3002</p> <pre><code>python fish_speech/train.py --config-name text2semantic_finetune \\\n    project=$project \\\n    +lora@model.model.lora_config=r_8_alpha_16\n</code></pre> <p>Note</p> <p><code>fish_speech/configs/text2semantic_finetune.yaml</code> \u3092\u5909\u66f4\u3057\u3066\u3001<code>batch_size</code>\u3001<code>gradient_accumulation_steps</code> \u306a\u3069\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u5909\u66f4\u3057\u3001GPU\u30e1\u30e2\u30ea\u306b\u9069\u5408\u3055\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</p> <p>Note</p> <p>Windows\u30e6\u30fc\u30b6\u30fc\u306e\u5834\u5408\u3001<code>trainer.strategy.process_group_backend=gloo</code> \u3092\u4f7f\u7528\u3057\u3066 <code>nccl</code> \u306e\u554f\u984c\u3092\u56de\u907f\u3067\u304d\u307e\u3059\u3002</p> <p>\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u304c\u5b8c\u4e86\u3057\u305f\u3089\u3001\u63a8\u8ad6\u30bb\u30af\u30b7\u30e7\u30f3\u3092\u53c2\u7167\u3057\u3001<code>--speaker SPK1</code> \u3092\u4f7f\u7528\u3057\u3066\u97f3\u58f0\u3092\u751f\u6210\u3057\u307e\u3059\u3002</p> <p>Info</p> <p>\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u3001\u30e2\u30c7\u30eb\u306f\u8a71\u8005\u306e\u767a\u8a71\u30d1\u30bf\u30fc\u30f3\u306e\u307f\u3092\u5b66\u7fd2\u3057\u3001\u97f3\u8272\u306f\u5b66\u7fd2\u3057\u307e\u305b\u3093\u3002\u97f3\u8272\u306e\u5b89\u5b9a\u6027\u3092\u78ba\u4fdd\u3059\u308b\u305f\u3081\u306b\u30d7\u30ed\u30f3\u30d7\u30c8\u3092\u4f7f\u7528\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002 \u97f3\u8272\u3092\u5b66\u7fd2\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30b9\u30c6\u30c3\u30d7\u6570\u3092\u5897\u3084\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u304c\u3001\u3053\u308c\u306b\u3088\u308a\u904e\u5b66\u7fd2\u304c\u767a\u751f\u3059\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002</p> <p>\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u304c\u5b8c\u4e86\u3057\u305f\u3089\u3001\u63a8\u8ad6\u3092\u884c\u3046\u524d\u306bLoRA\u306e\u91cd\u307f\u3092\u901a\u5e38\u306e\u91cd\u307f\u306b\u5909\u63db\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002</p> <pre><code>python tools/llama/merge_lora.py \\\n    --lora-config r_8_alpha_16 \\\n    --base-weight checkpoints/fish-speech-1.4 \\\n    --lora-weight results/$project/checkpoints/step_000000010.ckpt \\\n    --output checkpoints/fish-speech-1.4-yth-lora/\n</code></pre> <p>Note</p> <p>\u4ed6\u306e\u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c8\u3092\u8a66\u3059\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002\u8981\u4ef6\u3092\u6e80\u305f\u3059\u6700\u3082\u65e9\u3044\u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c8\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3092\u304a\u52e7\u3081\u3057\u307e\u3059\u3002\u3053\u308c\u3089\u306f\u901a\u5e38\u3001\u5206\u5e03\u5916\uff08OOD\uff09\u30c7\u30fc\u30bf\u3067\u3088\u308a\u826f\u3044\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u767a\u63ee\u3057\u307e\u3059\u3002</p>"},{"location":"ja/inference/","title":"\u63a8\u8ad6","text":"<p>\u63a8\u8ad6\u306f\u3001\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u3001HTTP API\u3001\u304a\u3088\u3073 Web UI \u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002</p> <p>Note</p> <p>\u5168\u4f53\u3068\u3057\u3066\u3001\u63a8\u8ad6\u306f\u6b21\u306e\u3044\u304f\u3064\u304b\u306e\u90e8\u5206\u3067\u69cb\u6210\u3055\u308c\u3066\u3044\u307e\u3059\uff1a</p> <ol> <li>VQGAN\u3092\u4f7f\u7528\u3057\u3066\u3001\u4e0e\u3048\u3089\u308c\u305f\u7d0410\u79d2\u306e\u97f3\u58f0\u3092\u30a8\u30f3\u30b3\u30fc\u30c9\u3057\u307e\u3059\u3002</li> <li>\u30a8\u30f3\u30b3\u30fc\u30c9\u3055\u308c\u305f\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30c8\u30fc\u30af\u30f3\u3068\u5bfe\u5fdc\u3059\u308b\u30c6\u30ad\u30b9\u30c8\u3092\u4f8b\u3068\u3057\u3066\u8a00\u8a9e\u30e2\u30c7\u30eb\u306b\u5165\u529b\u3057\u307e\u3059\u3002</li> <li>\u65b0\u3057\u3044\u30c6\u30ad\u30b9\u30c8\u304c\u4e0e\u3048\u3089\u308c\u305f\u5834\u5408\u3001\u30e2\u30c7\u30eb\u306b\u5bfe\u5fdc\u3059\u308b\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30c8\u30fc\u30af\u30f3\u3092\u751f\u6210\u3055\u305b\u307e\u3059\u3002</li> <li>\u751f\u6210\u3055\u308c\u305f\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30c8\u30fc\u30af\u30f3\u3092VITS / VQGAN\u306b\u5165\u529b\u3057\u3066\u30c7\u30b3\u30fc\u30c9\u3057\u3001\u5bfe\u5fdc\u3059\u308b\u97f3\u58f0\u3092\u751f\u6210\u3057\u307e\u3059\u3002</li> </ol>"},{"location":"ja/inference/#_2","title":"\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u63a8\u8ad6","text":"<p>\u5fc5\u8981\u306a<code>vqgan</code>\u304a\u3088\u3073<code>llama</code>\u30e2\u30c7\u30eb\u3092 Hugging Face \u30ea\u30dd\u30b8\u30c8\u30ea\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre>"},{"location":"ja/inference/#1","title":"1. \u97f3\u58f0\u304b\u3089\u30d7\u30ed\u30f3\u30d7\u30c8\u3092\u751f\u6210\u3059\u308b\uff1a","text":"<p>Note</p> <p>\u30e2\u30c7\u30eb\u306b\u30e9\u30f3\u30c0\u30e0\u306b\u97f3\u58f0\u306e\u97f3\u8272\u3092\u9078\u3070\u305b\u308b\u5834\u5408\u3001\u3053\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u30b9\u30ad\u30c3\u30d7\u3067\u304d\u307e\u3059\u3002</p> <pre><code>python tools/vqgan/inference.py \\\n    -i \"paimon.wav\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p><code>fake.npy</code>\u30d5\u30a1\u30a4\u30eb\u304c\u751f\u6210\u3055\u308c\u308b\u306f\u305a\u3067\u3059\u3002</p>"},{"location":"ja/inference/#2","title":"2. \u30c6\u30ad\u30b9\u30c8\u304b\u3089\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30c8\u30fc\u30af\u30f3\u3092\u751f\u6210\u3059\u308b\uff1a","text":"<pre><code>python tools/llama/generate.py \\\n    --text \"\u5909\u63db\u3057\u305f\u3044\u30c6\u30ad\u30b9\u30c8\" \\\n    --prompt-text \"\u53c2\u7167\u30c6\u30ad\u30b9\u30c8\" \\\n    --prompt-tokens \"fake.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --num-samples 2 \\\n    --compile\n</code></pre> <p>\u3053\u306e\u30b3\u30de\u30f3\u30c9\u306f\u3001\u4f5c\u696d\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b<code>codes_N</code>\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\u3053\u3053\u3067\u3001N \u306f 0 \u304b\u3089\u59cb\u307e\u308b\u6574\u6570\u3067\u3059\u3002</p> <p>Note</p> <p><code>--compile</code>\u3092\u4f7f\u7528\u3057\u3066 CUDA \u30ab\u30fc\u30cd\u30eb\u3092\u878d\u5408\u3057\u3001\u3088\u308a\u9ad8\u901f\u306a\u63a8\u8ad6\u3092\u5b9f\u73fe\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\uff08\u7d04 30 \u30c8\u30fc\u30af\u30f3/\u79d2 -&gt; \u7d04 500 \u30c8\u30fc\u30af\u30f3/\u79d2\uff09\u3002 \u305d\u308c\u306b\u5bfe\u5fdc\u3057\u3066\u3001\u52a0\u901f\u3092\u4f7f\u7528\u3057\u306a\u3044\u5834\u5408\u306f\u3001<code>--compile</code>\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u30b3\u30e1\u30f3\u30c8\u30a2\u30a6\u30c8\u3067\u304d\u307e\u3059\u3002</p> <p>Info</p> <p>bf16 \u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u306a\u3044 GPU \u306e\u5834\u5408\u3001<code>--half</code>\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u7528\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002</p>"},{"location":"ja/inference/#3","title":"3. \u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30c8\u30fc\u30af\u30f3\u304b\u3089\u97f3\u58f0\u3092\u751f\u6210\u3059\u308b\uff1a","text":""},{"location":"ja/inference/#vqgan","title":"VQGAN \u30c7\u30b3\u30fc\u30c0\u30fc","text":"<pre><code>python tools/vqgan/inference.py \\\n    -i \"codes_0.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre>"},{"location":"ja/inference/#http-api","title":"HTTP API \u63a8\u8ad6","text":"<p>\u63a8\u8ad6\u306e\u305f\u3081\u306e HTTP API \u3092\u63d0\u4f9b\u3057\u3066\u3044\u307e\u3059\u3002\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u7528\u3057\u3066\u30b5\u30fc\u30d0\u30fc\u3092\u8d77\u52d5\u3067\u304d\u307e\u3059\uff1a</p> <pre><code>python -m tools.api \\\n    --listen 0.0.0.0:8080 \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>\u63a8\u8ad6\u3092\u9ad8\u901f\u5316\u3057\u305f\u3044\u5834\u5408\u306f\u3001--compile \u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8ffd\u52a0\u3067\u304d\u307e\u3059\u3002</p> <p>\u305d\u306e\u5f8c\u3001<code>http://127.0.0.1:8080/</code>\u3067 API \u3092\u8868\u793a\u304a\u3088\u3073\u30c6\u30b9\u30c8\u3067\u304d\u307e\u3059\u3002</p> <p>\u4ee5\u4e0b\u306f\u3001<code>tools/post_api.py</code> \u3092\u4f7f\u7528\u3057\u3066\u30ea\u30af\u30a8\u30b9\u30c8\u3092\u9001\u4fe1\u3059\u308b\u4f8b\u3067\u3059\u3002</p> <pre><code>python -m tools.post_api \\\n    --text \"\u5165\u529b\u3059\u308b\u30c6\u30ad\u30b9\u30c8\" \\\n    --reference_audio \"\u53c2\u7167\u97f3\u58f0\u3078\u306e\u30d1\u30b9\" \\\n    --reference_text \"\u53c2\u7167\u97f3\u58f0\u30c6\u30ad\u30b9\u30c8\" \\\n    --streaming True\n</code></pre> <p>\u4e0a\u8a18\u306e\u30b3\u30de\u30f3\u30c9\u306f\u3001\u53c2\u7167\u97f3\u58f0\u306e\u60c5\u5831\u306b\u57fa\u3065\u3044\u3066\u5fc5\u8981\u306a\u97f3\u58f0\u3092\u5408\u6210\u3057\u3001\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0\u65b9\u5f0f\u3067\u8fd4\u3059\u3053\u3068\u3092\u793a\u3057\u3066\u3044\u307e\u3059\u3002</p> <p><code>{SPEAKER}</code>\u3068<code>{EMOTION}</code>\u306b\u57fa\u3065\u3044\u3066\u53c2\u7167\u97f3\u58f0\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u9078\u629e\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u5834\u5408\u306f\u3001\u4ee5\u4e0b\u306e\u624b\u9806\u306b\u5f93\u3063\u3066\u8a2d\u5b9a\u3057\u307e\u3059\uff1a</p>"},{"location":"ja/inference/#1-ref_data","title":"1. \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b<code>ref_data</code>\u30d5\u30a9\u30eb\u30c0\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002","text":""},{"location":"ja/inference/#2-ref_data","title":"2. <code>ref_data</code>\u30d5\u30a9\u30eb\u30c0\u5185\u306b\u6b21\u306e\u3088\u3046\u306a\u69cb\u9020\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002","text":"<pre><code>.\n\u251c\u2500\u2500 SPEAKER1\n\u2502    \u251c\u2500\u2500EMOTION1\n\u2502    \u2502    \u251c\u2500\u2500 21.15-26.44.lab\n\u2502    \u2502    \u251c\u2500\u2500 21.15-26.44.wav\n\u2502    \u2502    \u251c\u2500\u2500 27.51-29.98.lab\n\u2502    \u2502    \u251c\u2500\u2500 27.51-29.98.wav\n\u2502    \u2502    \u251c\u2500\u2500 30.1-32.71.lab\n\u2502    \u2502    \u2514\u2500\u2500 30.1-32.71.flac\n\u2502    \u2514\u2500\u2500EMOTION2\n\u2502         \u251c\u2500\u2500 30.1-32.71.lab\n\u2502         \u2514\u2500\u2500 30.1-32.71.mp3\n\u2514\u2500\u2500 SPEAKER2\n    \u2514\u2500\u2500\u2500 EMOTION3\n          \u251c\u2500\u2500 30.1-32.71.lab\n          \u2514\u2500\u2500 30.1-32.71.mp3\n</code></pre> <p>\u3064\u307e\u308a\u3001\u307e\u305a<code>ref_data</code>\u306b<code>{SPEAKER}</code>\u30d5\u30a9\u30eb\u30c0\u3092\u914d\u7f6e\u3057\u3001\u5404\u30b9\u30d4\u30fc\u30ab\u30fc\u306e\u4e0b\u306b<code>{EMOTION}</code>\u30d5\u30a9\u30eb\u30c0\u3092\u914d\u7f6e\u3057\u3001\u5404\u611f\u60c5\u30d5\u30a9\u30eb\u30c0\u306e\u4e0b\u306b\u4efb\u610f\u306e\u6570\u306e\u97f3\u58f0-\u30c6\u30ad\u30b9\u30c8\u30da\u30a2\u3092\u914d\u7f6e\u3057\u307e\u3059</p>"},{"location":"ja/inference/#3_1","title":"3. \u4eee\u60f3\u74b0\u5883\u3067\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5165\u529b\u3057\u307e\u3059.","text":"<pre><code>python tools/gen_ref.py\n</code></pre> <p>\u53c2\u7167\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u751f\u6210\u3057\u307e\u3059\u3002</p>"},{"location":"ja/inference/#4-api","title":"4. API \u3092\u547c\u3073\u51fa\u3057\u307e\u3059\u3002","text":"<pre><code>python -m tools.post_api \\\n    --text \"\u5165\u529b\u3059\u308b\u30c6\u30ad\u30b9\u30c8\" \\\n    --speaker \"${SPEAKER1}\" \\\n    --emotion \"${EMOTION1}\" \\\n    --streaming True\n</code></pre> <p>\u4e0a\u8a18\u306e\u4f8b\u306f\u30c6\u30b9\u30c8\u76ee\u7684\u306e\u307f\u3067\u3059\u3002</p>"},{"location":"ja/inference/#webui","title":"WebUI \u63a8\u8ad6","text":"<p>\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u7528\u3057\u3066 WebUI \u3092\u8d77\u52d5\u3067\u304d\u307e\u3059\uff1a</p> <pre><code>python -m tools.webui \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>Note</p> <p>Gradio \u74b0\u5883\u5909\u6570\uff08<code>GRADIO_SHARE</code>\u3001<code>GRADIO_SERVER_PORT</code>\u3001<code>GRADIO_SERVER_NAME</code>\u306a\u3069\uff09\u3092\u4f7f\u7528\u3057\u3066 WebUI \u3092\u69cb\u6210\u3067\u304d\u307e\u3059\u3002</p> <p>\u304a\u697d\u3057\u307f\u304f\u3060\u3055\u3044\uff01</p>"},{"location":"ja/samples/","title":"\u30b5\u30f3\u30d7\u30eb","text":"<p>v1.2\u306e\u30b5\u30f3\u30d7\u30eb\u306fBilibili\u3067\u5229\u7528\u53ef\u80fd\u3067\u3059\u3002</p> <p>\u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u306fv1.1\u30e2\u30c7\u30eb\u304b\u3089\u306e\u3082\u306e\u3067\u3059\u3002</p>"},{"location":"ja/samples/#1","title":"\u4e2d\u56fd\u8a9e\u306e\u65871","text":"<pre><code>\u4eba\u9593\u706f\u706b\u5012\u6620\u6e56\u4e2d\uff0c\u5979\u7684\u6e34\u671b\u8ba9\u9759\u6c34\u6cdb\u8d77\u6d9f\u6f2a\u3002\u82e5\u4ee3\u4ef7\u53ea\u662f\u5b64\u72ec\uff0c\u90a3\u5c31\u8ba9\u8fd9\u4efd\u613f\u671b\u8086\u610f\u6d41\u6dcc\u3002\n\u6d41\u5165\u5979\u6240\u6ce8\u89c6\u7684\u4e16\u95f4\uff0c\u4e5f\u6d41\u5165\u5979\u5982\u6e56\u6c34\u822c\u6f84\u6f88\u7684\u76ee\u5149\u3002\n</code></pre> \u8a71\u8005 \u5165\u529b\u97f3\u58f0 \u5408\u6210\u97f3\u58f0 \u30ca\u30d2\u30fc\u30c0 (\u539f\u795e) \u937e\u96e2 (\u539f\u795e) \u30d5\u30ea\u30ca (\u539f\u795e) \u30e9\u30f3\u30c0\u30e0\u8a71\u80051  -  \u30e9\u30f3\u30c0\u30e0\u8a71\u80052  -"},{"location":"ja/samples/#2","title":"\u4e2d\u56fd\u8a9e\u306e\u65872","text":"<pre><code>\u4f60\u4eec\u8fd9\u4e2a\u662f\u4ec0\u4e48\u7fa4\u554a\uff0c\u4f60\u4eec\u8fd9\u662f\u5bb3\u4eba\u4e0d\u6d45\u554a\u4f60\u4eec\u8fd9\u4e2a\u7fa4\uff01\u8c01\u662f\u7fa4\u4e3b\uff0c\u51fa\u6765\uff01\u771f\u7684\u592a\u8fc7\u5206\u4e86\u3002\u4f60\u4eec\u641e\u8fd9\u4e2a\u7fa4\u5e72\u4ec0\u4e48\uff1f\n\u6211\u513f\u5b50\u6bcf\u4e00\u79d1\u7684\u6210\u7ee9\u90fd\u4e0d\u8fc7\u90a3\u4e2a\u5e73\u5747\u5206\u5450\uff0c\u4ed6\u73b0\u5728\u521d\u4e8c\uff0c\u4f60\u53eb\u6211\u513f\u5b50\u600e\u4e48\u529e\u554a\uff1f\u4ed6\u73b0\u5728\u8fd8\u4e0d\u5230\u9ad8\u4e2d\u554a\uff1f\n\u4f60\u4eec\u5bb3\u6b7b\u6211\u513f\u5b50\u4e86\uff01\u5feb\u70b9\u51fa\u6765\u4f60\u8fd9\u4e2a\u7fa4\u4e3b\uff01\u518d\u8fd9\u6837\u6211\u53bb\u62a5\u8b66\u4e86\u554a\uff01\u6211\u8ddf\u4f60\u4eec\u8bf4\u4f60\u4eec\u8fd9\u4e00\u5e2e\u4eba\u554a\uff0c\u4e00\u5929\u5230\u665a\u554a\uff0c\n\u641e\u8fd9\u4e9b\u4ec0\u4e48\u6e38\u620f\u554a\uff0c\u52a8\u6f2b\u554a\uff0c\u4f1a\u5bb3\u6b7b\u4f60\u4eec\u7684\uff0c\u4f60\u4eec\u6ca1\u6709\u524d\u9014\u6211\u8ddf\u4f60\u8bf4\u3002\u4f60\u4eec\u8fd9\u4e5d\u767e\u591a\u4e2a\u4eba\uff0c\u597d\u597d\u5b66\u4e60\u4e0d\u597d\u5417\uff1f\n\u4e00\u5929\u5230\u665a\u5728\u4e0a\u7f51\u3002\u6709\u4ec0\u4e48\u610f\u601d\u554a\uff1f\u9ebb\u70e6\u4f60\u91cd\u89c6\u4e00\u4e0b\u4f60\u4eec\u7684\u751f\u6d3b\u7684\u76ee\u6807\u554a\uff1f\u6709\u4e00\u70b9\u5b66\u4e60\u76ee\u6807\u884c\u4e0d\u884c\uff1f\u4e00\u5929\u5230\u665a\u4e0a\u7f51\u662f\u4e0d\u662f\u4eba\u554a\uff1f\n</code></pre> \u8a71\u8005 \u5165\u529b\u97f3\u58f0 \u5408\u6210\u97f3\u58f0 \u30ca\u30d2\u30fc\u30c0 (\u539f\u795e) \u30e9\u30f3\u30c0\u30e0\u8a71\u8005  -"},{"location":"ja/samples/#3","title":"\u4e2d\u56fd\u8a9e\u306e\u65873","text":"<pre><code>\u5927\u5bb6\u597d\uff0c\u6211\u662f Fish Audio \u5f00\u53d1\u7684\u5f00\u6e90\u6587\u672c\u8f6c\u8bed\u97f3\u6a21\u578b\u3002\u7ecf\u8fc7\u5341\u4e94\u4e07\u5c0f\u65f6\u7684\u6570\u636e\u8bad\u7ec3\uff0c\n\u6211\u5df2\u7ecf\u80fd\u591f\u719f\u7ec3\u638c\u63e1\u4e2d\u6587\u3001\u65e5\u8bed\u548c\u82f1\u8bed\uff0c\u6211\u7684\u8bed\u8a00\u5904\u7406\u80fd\u529b\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0c\u58f0\u97f3\u8868\u73b0\u5f62\u5f0f\u4e30\u5bcc\u591a\u53d8\u3002\n\u4f5c\u4e3a\u4e00\u4e2a\u4ec5\u6709\u4ebf\u7ea7\u53c2\u6570\u7684\u6a21\u578b\uff0c\u6211\u76f8\u4fe1\u793e\u533a\u6210\u5458\u80fd\u591f\u5728\u4e2a\u4eba\u8bbe\u5907\u4e0a\u8f7b\u677e\u8fd0\u884c\u548c\u5fae\u8c03\uff0c\u8ba9\u6211\u6210\u4e3a\u60a8\u7684\u79c1\u4eba\u8bed\u97f3\u52a9\u624b\u3002\n</code></pre> \u8a71\u8005 \u5165\u529b\u97f3\u58f0 \u5408\u6210\u97f3\u58f0 \u30e9\u30f3\u30c0\u30e0\u8a71\u8005  -"},{"location":"ja/samples/#1_1","title":"\u82f1\u8a9e\u306e\u65871","text":"<pre><code>In the realm of advanced technology, the evolution of artificial intelligence stands as a \nmonumental achievement. This dynamic field, constantly pushing the boundaries of what \nmachines can do, has seen rapid growth and innovation. From deciphering complex data \npatterns to driving cars autonomously, AI's applications are vast and diverse.\n</code></pre> \u8a71\u8005 \u5165\u529b\u97f3\u58f0 \u5408\u6210\u97f3\u58f0 \u30e9\u30f3\u30c0\u30e0\u8a71\u80051  -  \u30e9\u30f3\u30c0\u30e0\u8a71\u80052  -"},{"location":"ja/samples/#2_1","title":"\u82f1\u8a9e\u306e\u65872","text":"<pre><code>Hello everyone, I am an open-source text-to-speech model developed by \nFish Audio. After training with 150,000 hours of data, I have become proficient \nin Chinese, Japanese, and English, and my language processing abilities \nare close to human level. My voice is capable of a wide range of expressions. \nAs a model with only hundreds of millions of parameters, I believe community \nmembers can easily run and fine-tune me on their personal devices, allowing \nme to serve as your personal voice assistant.\n</code></pre> \u8a71\u8005 \u5165\u529b\u97f3\u58f0 \u5408\u6210\u97f3\u58f0 \u30e9\u30f3\u30c0\u30e0\u8a71\u8005  -"},{"location":"ja/samples/#1_2","title":"\u65e5\u672c\u8a9e\u306e\u65871","text":"<pre><code>\u5148\u9032\u6280\u8853\u306e\u9818\u57df\u306b\u304a\u3044\u3066\u3001\u4eba\u5de5\u77e5\u80fd\u306e\u9032\u5316\u306f\u753b\u671f\u7684\u306a\u6210\u679c\u3068\u3057\u3066\u7acb\u3063\u3066\u3044\u307e\u3059\u3002\u5e38\u306b\u6a5f\u68b0\u304c\u3067\u304d\u308b\u3053\u3068\u306e\u9650\u754c\u3092\n\u62bc\u3057\u5e83\u3052\u3066\u3044\u308b\u3053\u306e\u30c0\u30a4\u30ca\u30df\u30c3\u30af\u306a\u5206\u91ce\u306f\u3001\u6025\u901f\u306a\u6210\u9577\u3068\u9769\u65b0\u3092\u898b\u305b\u3066\u3044\u307e\u3059\u3002\u8907\u96d1\u306a\u30c7\u30fc\u30bf\u30d1\u30bf\u30fc\u30f3\u306e\u89e3\u8aad\u304b\n\u3089\u81ea\u52d5\u904b\u8ee2\u8eca\u306e\u64cd\u7e26\u307e\u3067\u3001AI\u306e\u5fdc\u7528\u306f\u5e83\u7bc4\u56f2\u306b\u53ca\u3073\u307e\u3059\u3002\n</code></pre> \u8a71\u8005 \u5165\u529b\u97f3\u58f0 \u5408\u6210\u97f3\u58f0 \u30e9\u30f3\u30c0\u30e0\u8a71\u80051  -  \u30e9\u30f3\u30c0\u30e0\u8a71\u80052  -"},{"location":"ja/samples/#2_2","title":"\u65e5\u672c\u8a9e\u306e\u65872","text":"<pre><code>\u7686\u3055\u3093\u3001\u3053\u3093\u306b\u3061\u306f\u3002\u79c1\u306f\u30d5\u30a3\u30c3\u30b7\u30e5\u30aa\u30fc\u30c7\u30a3\u30aa\u306b\u3088\u3063\u3066\u958b\u767a\u3055\u308c\u305f\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u306e\u30c6\n\u30ad\u30b9\u30c8\u304b\u3089\u97f3\u58f0\u3078\u306e\u5909\u63db\u30e2\u30c7\u30eb\u3067\u3059\u300215\u4e07\u6642\u9593\u306e\u30c7\u30fc\u30bf\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u7d4c\u3066\u3001\n\u4e2d\u56fd\u8a9e\u3001\u65e5\u672c\u8a9e\u3001\u82f1\u8a9e\u3092\u719f\u77e5\u3057\u3066\u304a\u308a\u3001\u8a00\u8a9e\u51e6\u7406\u80fd\u529b\u306f\u4eba\u9593\u306b\u8fd1\u3044\u30ec\u30d9\u30eb\u3067\u3059\u3002\n\u58f0\u306e\u8868\u73fe\u3082\u591a\u5f69\u3067\u8c4a\u304b\u3067\u3059\u3002\u6570\u5104\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6301\u3064\u3053\u306e\u30e2\u30c7\u30eb\u306f\u3001\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\n\u306e\u30e1\u30f3\u30d0\u30fc\u304c\u500b\u4eba\u306e\u30c7\u30d0\u30a4\u30b9\u3067\u7c21\u5358\u306b\u5b9f\u884c\u3057\u3001\u5fae\u8abf\u6574\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3068\n\u4fe1\u3058\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u79c1\u3092\u500b\u4eba\u306e\u97f3\u58f0\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3068\u3057\u3066\u6d3b\u7528\u3067\u304d\u307e\u3059\u3002\n</code></pre> \u8a71\u8005 \u5165\u529b\u97f3\u58f0 \u5408\u6210\u97f3\u58f0 \u30e9\u30f3\u30c0\u30e0\u8a71\u8005  -"},{"location":"pt/","title":"Introdu\u00e7\u00e3o","text":"<p>Warning</p> <p>N\u00e3o nos responsabilizamos por qualquer uso ilegal do c\u00f3digo-fonte. Consulte as leis locais sobre DMCA (Digital Millennium Copyright Act) e outras leis relevantes em sua regi\u00e3o.  Este reposit\u00f3rio de c\u00f3digo e os modelos s\u00e3o distribu\u00eddos sob a licen\u00e7a CC-BY-NC-SA-4.0.</p> <p> </p>"},{"location":"pt/#requisitos","title":"Requisitos","text":"<ul> <li>Mem\u00f3ria da GPU: 4GB (para infer\u00eancia), 8GB (para ajuste fino)</li> <li>Sistema: Linux, Windows</li> </ul>"},{"location":"pt/#configuracao-para-windows","title":"Configura\u00e7\u00e3o para Windows","text":"<p>No Windows, usu\u00e1rios avan\u00e7ados podem considerar usar o WSL2 ou Docker para executar o c\u00f3digo.</p> <p>Para Usu\u00e1rios comuns (n\u00e3o-avan\u00e7ados), siga os m\u00e9todos abaixo para executar o c\u00f3digo sem um ambiente Linux (incluindo suporte para <code>torch.compile</code>):</p> <ol> <li>Extraia o arquivo compactado do projeto.</li> <li>Prepare o ambiente conda:     <ul> <li>Abra o <code>install_env.bat</code> para baixar e iniciar a instala\u00e7\u00e3o do miniconda.</li> <li>Personalize o download (opcional):         <ul> <li>**Site espelho:** Para usar um site espelho para downloads mais r\u00e1pidos, defina <code>USE_MIRROR=true</code> no <code>install_env.bat</code> (padr\u00e3o). Caso contr\u00e1rio, use <code>USE_MIRROR=false</code>.</li> <li>**Ambiente compilado:** Para baixar a vers\u00e3o de pr\u00e9via com o ambiente compilado, defina <code>INSTALL_TYPE=preview</code>. Para a vers\u00e3o est\u00e1vel sem ambiente compilado, use <code>INSTALL_TYPE=stable</code>.</li> </ul> </li> </ul> </li> <li>Se voc\u00ea escolheu a vers\u00e3o de pr\u00e9via com ambiente compilado (<code>INSTALL_TYPE=preview</code>), siga para a pr\u00f3xima etapa (opcional):       <ol> <li>Baixe o compilador LLVM usando os seguintes links:                <ul> <li>LLVM-17.0.6 (download do site original)</li> <li>LLVM-17.0.6 (download do site espelho)</li> <li>Ap\u00f3s baixar o <code>LLVM-17.0.6-win64.exe</code>, clique duas vezes para instal\u00e1-lo, escolha um local de instala\u00e7\u00e3o apropriado. E durante a instala\u00e7\u00e3o, marque a op\u00e7\u00e3o <code>Add Path to Current User</code> para adicionar \u00e0s vari\u00e1veis de ambiente.</li> <li>Confirme se a instala\u00e7\u00e3o foi conclu\u00edda.</li> </ul> </li> <li>Baixe e instale o pacote Microsoft Visual C++ Redistributable para resolver poss\u00edveis problemas de .dll ausentes.                <ul> <li>Download do MSVC++ 14.40.33810.0</li> </ul> </li> <li>Baixe e instale o Visual Studio Community Edition para obter as ferramentas de compila\u00e7\u00e3o MSVC++, resolvendo as depend\u00eancias do arquivo de cabe\u00e7alho LLVM.                <ul> <li>Download do Visual Studio</li> <li>Ap\u00f3s instalar o Visual Studio Installer, baixe o Visual Studio Community 2022.</li> <li>Clique no bot\u00e3o <code>Modificar</code>, conforme mostrado abaixo, encontre a op\u00e7\u00e3o <code>Desenvolvimento para desktop com C++</code> e marque-a para download.</li> <p> </p> </ul> </li> <li>Instale o CUDA Toolkit 12</li> </ol> </li> <li>Clique duas vezes em <code>start.bat</code> para entrar na p\u00e1gina da WebUI de configura\u00e7\u00e3o de infer\u00eancia de treinamento do Fish-Speech.       <ul> <li>(Opcional) Se desejar ir direto para a p\u00e1gina de infer\u00eancia, edite o arquivo <code>API_FLAGS.txt</code> no diret\u00f3rio raiz do projeto e modifique as tr\u00eas primeiras linhas da seguinte forma:                <pre><code>--infer\n# --api\n# --listen ...\n...</code></pre> </li> <li>(Opcional) Se preferir iniciar o servidor da API, edite o arquivo <code>API_FLAGS.txt</code> no diret\u00f3rio raiz do projeto e modifique as tr\u00eas primeiras linhas da seguinte forma:                <pre><code># --infer\n--api\n--listen ...\n...</code></pre> </li> </ul> </li> <li>(Opcional) Clique duas vezes em <code>run_cmd.bat</code> para entrar na CLI do conda/python deste projeto.</li> </ol>"},{"location":"pt/#configuracao-para-linux","title":"Configura\u00e7\u00e3o para Linux","text":"<pre><code># Crie um ambiente virtual python 3.10, voc\u00ea tamb\u00e9m pode usar virtualenv\nconda create -n fish-speech python=3.10\nconda activate fish-speech\n\n# Instale o pytorch\npip3 install torch torchvision torchaudio\n\n# Instale o fish-speech\npip3 install -e .[stable]\n\n# Para os Usu\u00e1rio do Ubuntu / Debian: Instale o sox\napt install libsox-dev\n</code></pre>"},{"location":"pt/#historico-de-alteracoes","title":"Hist\u00f3rico de Altera\u00e7\u00f5es","text":"<ul> <li>02/07/2024: Fish-Speech atualizado para a vers\u00e3o 1.2, removido o Decodificador VITS e aprimorado consideravelmente a capacidade de zero-shot.</li> <li>10/05/2024: Fish-Speech atualizado para a vers\u00e3o 1.1, implementado o decodificador VITS para reduzir a WER e melhorar a similaridade de timbre.</li> <li>22/04/2024: Finalizada a vers\u00e3o 1.0 do Fish-Speech, modificados significativamente os modelos VQGAN e LLAMA.</li> <li>28/12/2023: Adicionado suporte para ajuste fino <code>lora</code>.</li> <li>27/12/2023: Adicionado suporte para <code>gradient checkpointing</code>, <code>causual sampling</code> e <code>flash-attn</code>.</li> <li>19/12/2023: Atualizada a interface web e a API HTTP.</li> <li>18/12/2023: Atualizada a documenta\u00e7\u00e3o de ajuste fino e exemplos relacionados.</li> <li>17/12/2023: Atualizado o modelo <code>text2semantic</code>, suportando o modo sem fonemas.</li> <li>13/12/2023: Vers\u00e3o beta lan\u00e7ada, incluindo o modelo VQGAN e um modelo de linguagem baseado em LLAMA (suporte apenas a fonemas).</li> </ul>"},{"location":"pt/#agradecimentos","title":"Agradecimentos","text":"<ul> <li>VITS2 (daniilrobnikov)</li> <li>Bert-VITS2</li> <li>GPT VITS</li> <li>MQTTS</li> <li>GPT Fast</li> <li>Transformers</li> <li>GPT-SoVITS</li> </ul>"},{"location":"pt/finetune/","title":"Ajuste Fino","text":"<p>\u00c9 \u00f3bvio que ao abrir esta p\u00e1gina, voc\u00ea n\u00e3o deve estar muito satisfeito com o desempenho do modelo pr\u00e9-treinado com poucos exemplos. Voc\u00ea pode querer ajustar o modelo para melhorar seu desempenho em seu conjunto de dados.</p> <p>Na atual vers\u00e3o, a \u00fanica coisa que voc\u00ea precisa ajustar \u00e9 a parte do 'LLAMA'.</p>"},{"location":"pt/finetune/#ajuste-fino-do-llama","title":"Ajuste Fino do LLAMA","text":""},{"location":"pt/finetune/#1-preparando-o-conjunto-de-dados","title":"1. Preparando o conjunto de dados","text":"<pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u2514\u2500\u2500 30.1-32.71.mp3\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u2514\u2500\u2500 38.79-40.85.mp3\n</code></pre> <p>Voc\u00ea precisa converter seu conjunto de dados para o formato acima e coloc\u00e1-lo em <code>data</code>. O arquivo de \u00e1udio pode ter as extens\u00f5es <code>.mp3</code>, <code>.wav</code> ou <code>.flac</code>, e o arquivo de anota\u00e7\u00e3o deve ter a extens\u00e3o <code>.lab</code>.</p> <p>Warning</p> <p>\u00c9 recomendado aplicar normaliza\u00e7\u00e3o de volume ao conjunto de dados. Voc\u00ea pode usar o fish-audio-preprocess para fazer isso.</p> <pre><code>fap loudness-norm data-raw data --clean\n</code></pre>"},{"location":"pt/finetune/#2-extracao-em-lote-de-tokens-semanticos","title":"2. Extra\u00e7\u00e3o em lote de tokens sem\u00e2nticos","text":"<p>Certifique-se de ter baixado os pesos do VQGAN. Se n\u00e3o, execute o seguinte comando:</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>Em seguida, voc\u00ea pode executar o seguinte comando para extrair os tokens sem\u00e2nticos:</p> <pre><code>python tools/vqgan/extract_vq.py data \\\n    --num-workers 1 --batch-size 16 \\\n    --config-name \"firefly_gan_vq\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>Note</p> <p>Voc\u00ea pode ajustar <code>--num-workers</code> e <code>--batch-size</code> para aumentar a velocidade de extra\u00e7\u00e3o, mas certifique-se de n\u00e3o exceder o limite de mem\u00f3ria da sua GPU. \u00a0 Para o formato VITS, voc\u00ea pode especificar uma lista de arquivos usando <code>--filelist xxx.list</code>.</p> <p>Este comando criar\u00e1 arquivos <code>.npy</code> no diret\u00f3rio <code>data</code>, como mostrado abaixo:</p> <pre><code>.\n\u251c\u2500\u2500 SPK1\n\u2502   \u251c\u2500\u2500 21.15-26.44.lab\n\u2502   \u251c\u2500\u2500 21.15-26.44.mp3\n\u2502   \u251c\u2500\u2500 21.15-26.44.npy\n\u2502   \u251c\u2500\u2500 27.51-29.98.lab\n\u2502   \u251c\u2500\u2500 27.51-29.98.mp3\n\u2502   \u251c\u2500\u2500 27.51-29.98.npy\n\u2502   \u251c\u2500\u2500 30.1-32.71.lab\n\u2502   \u251c\u2500\u2500 30.1-32.71.mp3\n\u2502   \u2514\u2500\u2500 30.1-32.71.npy\n\u2514\u2500\u2500 SPK2\n    \u251c\u2500\u2500 38.79-40.85.lab\n    \u251c\u2500\u2500 38.79-40.85.mp3\n    \u2514\u2500\u2500 38.79-40.85.npy\n</code></pre>"},{"location":"pt/finetune/#3-empacotar-o-conjunto-de-dados-em-protobuf","title":"3. Empacotar o conjunto de dados em protobuf","text":"<pre><code>python tools/llama/build_dataset.py \\\n    --input \"data\" \\\n    --output \"data/protos\" \\\n    --text-extension .lab \\\n    --num-workers 16\n</code></pre> <p>Ap\u00f3s executar o comando, voc\u00ea dever\u00e1 ver o arquivo <code>quantized-dataset-ft.protos</code> no diret\u00f3rio <code>data</code>.</p>"},{"location":"pt/finetune/#4-e-finalmente-chegamos-ao-ajuste-fino-com-lora","title":"4. E finalmente, chegamos ao ajuste fino com LoRA","text":"<p>Da mesma forma, certifique-se de ter baixado os pesos do <code>LLAMA</code>. Se n\u00e3o, execute o seguinte comando:</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre> <p>E ent\u00e3o, execute o seguinte comando para iniciar o ajuste fino:</p> <pre><code>python fish_speech/train.py --config-name text2semantic_finetune \\\n    project=$project \\\n    +lora@model.model.lora_config=r_8_alpha_16\n</code></pre> <p>Note</p> <p>Se quiser, voc\u00ea pode modificar os par\u00e2metros de treinamento, como <code>batch_size</code>, <code>gradient_accumulation_steps</code>, etc., para se ajustar \u00e0 mem\u00f3ria da sua GPU, modificando <code>fish_speech/configs/text2semantic_finetune.yaml</code>.</p> <p>Note</p> <p>Para usu\u00e1rios do Windows, \u00e9 recomendado usar <code>trainer.strategy.process_group_backend=gloo</code> para evitar problemas com <code>nccl</code>.</p> <p>Ap\u00f3s concluir o treinamento, consulte a se\u00e7\u00e3o infer\u00eancia, e use <code>--speaker SPK1</code> para gerar fala.</p> <p>Info</p> <p>Por padr\u00e3o, o modelo aprender\u00e1 apenas os padr\u00f5es de fala do orador e n\u00e3o o timbre. Ainda pode ser preciso usar prompts para garantir a estabilidade do timbre. Se quiser que ele aprenda o timbre, aumente o n\u00famero de etapas de treinamento, mas isso pode levar ao overfitting (sobreajuste).</p> <p>Ap\u00f3s o treinamento, \u00e9 preciso converter os pesos do LoRA em pesos regulares antes de realizar a infer\u00eancia.</p> <pre><code>python tools/llama/merge_lora.py \\\n    --lora-config r_8_alpha_16 \\\n    --base-weight checkpoints/fish-speech-1.4 \\\n    --lora-weight results/$project/checkpoints/step_000000010.ckpt \\\n    --output checkpoints/fish-speech-1.4-yth-lora/\n</code></pre> <p>Note</p> <p>\u00c9 poss\u00edvel tamb\u00e9m tentar outros checkpoints. Sugerimos usar o checkpoint que melhor atenda aos seus requisitos, pois eles geralmente t\u00eam um desempenho melhor em dados fora da distribui\u00e7\u00e3o (OOD).</p>"},{"location":"pt/inference/","title":"Infer\u00eancia","text":"<p>Suporte para infer\u00eancia por linha de comando, API HTTP e interface web (WebUI).</p> <p>Note</p> <p>O processo de racioc\u00ednio, em geral, consiste em v\u00e1rias partes:</p> <ol> <li>Codificar cerca de 10 segundos de voz usando VQGAN.</li> <li>Inserir os tokens sem\u00e2nticos codificados e o texto correspondente no modelo de linguagem como um exemplo.</li> <li>Dado um novo trecho de texto, fazer com que o modelo gere os tokens sem\u00e2nticos correspondentes.</li> <li>Inserir os tokens sem\u00e2nticos gerados no VITS / VQGAN para decodificar e gerar a voz correspondente.</li> </ol>"},{"location":"pt/inference/#inferencia-por-linha-de-comando","title":"Infer\u00eancia por Linha de Comando","text":"<p>Baixe os modelos <code>vqgan</code> e <code>llama</code> necess\u00e1rios do nosso reposit\u00f3rio Hugging Face.</p> <pre><code>huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4\n</code></pre>"},{"location":"pt/inference/#1-gerar-prompt-a-partir-da-voz","title":"1. Gerar prompt a partir da voz:","text":"<p>Note</p> <p>Se quiser permitir que o modelo escolha aleatoriamente um timbre de voz, pule esta etapa.</p> <pre><code>python tools/vqgan/inference.py \\\n    -i \"paimon.wav\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre> <p>Voc\u00ea dever\u00e1 obter um arquivo <code>fake.npy</code>.</p>"},{"location":"pt/inference/#2-gerar-tokens-semanticos-a-partir-do-texto","title":"2. Gerar tokens sem\u00e2nticos a partir do texto:","text":"<pre><code>python tools/llama/generate.py \\\n    --text \"O texto que voc\u00ea deseja converter\" \\\n    --prompt-text \"Seu texto de refer\u00eancia\" \\\n    --prompt-tokens \"fake.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --num-samples 2 \\\n    --compile\n</code></pre> <p>Este comando criar\u00e1 um arquivo <code>codes_N</code> no diret\u00f3rio de trabalho, onde N \u00e9 um n\u00famero inteiro come\u00e7ando de 0.</p> <p>Note</p> <p>Use <code>--compile</code> para fundir kernels CUDA para ter uma infer\u00eancia mais r\u00e1pida (~30 tokens/segundo -&gt; ~500 tokens/segundo). Mas, se n\u00e3o planeja usar a acelera\u00e7\u00e3o CUDA, comente o par\u00e2metro <code>--compile</code>.</p> <p>Info</p> <p>Para GPUs que n\u00e3o suportam bf16, pode ser necess\u00e1rio usar o par\u00e2metro <code>--half</code>.</p>"},{"location":"pt/inference/#3-gerar-vocais-a-partir-de-tokens-semanticos","title":"3. Gerar vocais a partir de tokens sem\u00e2nticos:","text":""},{"location":"pt/inference/#decodificador-vqgan","title":"Decodificador VQGAN","text":"<pre><code>python tools/vqgan/inference.py \\\n    -i \"codes_0.npy\" \\\n    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n</code></pre>"},{"location":"pt/inference/#inferencia-por-api-http","title":"Infer\u00eancia por API HTTP","text":"<p>Fornecemos uma API HTTP para infer\u00eancia. O seguinte comando pode ser usado para iniciar o servidor:</p> <pre><code>python -m tools.api \\\n    --listen 0.0.0.0:8080 \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>Para acelerar a infer\u00eancia, adicione o par\u00e2metro <code>--compile</code>.</p> <p>Depois disso, \u00e9 poss\u00edvel visualizar e testar a API em http://127.0.0.1:8080/.</p> <p>Abaixo est\u00e1 um exemplo de envio de uma solicita\u00e7\u00e3o usando <code>tools/post_api.py</code>.</p> <pre><code>python -m tools.post_api \\\n    --text \"Texto a ser inserido\" \\\n    --reference_audio \"Caminho para o \u00e1udio de refer\u00eancia\" \\\n    --reference_text \"Conte\u00fado de texto do \u00e1udio de refer\u00eancia\" \\\n    --streaming True\n</code></pre> <p>O comando acima indica a s\u00edntese do \u00e1udio desejada de acordo com as informa\u00e7\u00f5es do \u00e1udio de refer\u00eancia e a retorna em modo de streaming.</p> <p>Caso selecione, de forma aleat\u00f3ria, o \u00e1udio de refer\u00eancia com base em <code>{SPEAKER}</code> e <code>{EMOTION}</code>, o configure de acordo com as seguintes etapas:</p>"},{"location":"pt/inference/#1-crie-uma-pasta-ref_data-no-diretorio-raiz-do-projeto","title":"1. Crie uma pasta <code>ref_data</code> no diret\u00f3rio raiz do projeto.","text":""},{"location":"pt/inference/#2-crie-uma-estrutura-de-diretorios-semelhante-a-seguinte-dentro-da-pasta-ref_data","title":"2. Crie uma estrutura de diret\u00f3rios semelhante \u00e0 seguinte dentro da pasta <code>ref_data</code>.","text":"<pre><code>.\n\u251c\u2500\u2500 SPEAKER1\n\u2502    \u251c\u2500\u2500EMOTION1\n\u2502    \u2502    \u251c\u2500\u2500 21.15-26.44.lab\n\u2502    \u2502    \u251c\u2500\u2500 21.15-26.44.wav\n\u2502    \u2502    \u251c\u2500\u2500 27.51-29.98.lab\n\u2502    \u2502    \u251c\u2500\u2500 27.51-29.98.wav\n\u2502    \u2502    \u251c\u2500\u2500 30.1-32.71.lab\n\u2502    \u2502    \u2514\u2500\u2500 30.1-32.71.flac\n\u2502    \u2514\u2500\u2500EMOTION2\n\u2502         \u251c\u2500\u2500 30.1-32.71.lab\n\u2502         \u2514\u2500\u2500 30.1-32.71.mp3\n\u2514\u2500\u2500 SPEAKER2\n    \u2514\u2500\u2500\u2500 EMOTION3\n          \u251c\u2500\u2500 30.1-32.71.lab\n          \u2514\u2500\u2500 30.1-32.71.mp3\n</code></pre> <p>Ou seja, primeiro coloque as pastas <code>{SPEAKER}</code> em <code>ref_data</code>, depois coloque as pastas <code>{EMOTION}</code> em cada pasta de orador (speaker) e coloque qualquer n\u00famero de <code>pares \u00e1udio-texto</code> em cada pasta de emo\u00e7\u00e3o.</p>"},{"location":"pt/inference/#3-digite-o-seguinte-comando-no-ambiente-virtual","title":"3. Digite o seguinte comando no ambiente virtual","text":"<pre><code>python tools/gen_ref.py\n</code></pre>"},{"location":"pt/inference/#4-chame-a-api","title":"4. Chame a API.","text":"<pre><code>python -m tools.post_api \\\n    --text \"Texto a ser inserido\" \\\n    --speaker \"${SPEAKER1}\" \\\n    --emotion \"${EMOTION1}\" \\\n    --streaming True\n</code></pre> <p>O exemplo acima \u00e9 apenas para fins de teste.</p>"},{"location":"pt/inference/#inferencia-por-webui","title":"Infer\u00eancia por WebUI","text":"<p>Para iniciar a WebUI de Infer\u00eancia execute o seguinte comando:</p> <pre><code>python -m tools.webui \\\n    --llama-checkpoint-path \"checkpoints/fish-speech-1.4\" \\\n    --decoder-checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" \\\n    --decoder-config-name firefly_gan_vq\n</code></pre> <p>Note</p> <p>\u00c9 poss\u00edvel usar vari\u00e1veis de ambiente do Gradio, como <code>GRADIO_SHARE</code>, <code>GRADIO_SERVER_PORT</code>, <code>GRADIO_SERVER_NAME</code>, para configurar a WebUI.</p> <p>Divirta-se!</p>"},{"location":"pt/samples/","title":"Amostras","text":"<p>As amostras da v1.2 est\u00e3o dispon\u00edveis em Bilibili.</p> <p>As seguintes amostras s\u00e3o do modelo v1.1.</p>"},{"location":"pt/samples/#frase-em-chines-1","title":"Frase em Chin\u00eas 1","text":"<pre><code>\u4eba\u95f4\u706f\u706b\u5012\u6620\u6e56\u4e2d\uff0c\u5979\u7684\u6e34\u671b\u8ba9\u9759\u6c34\u6cdb\u8d77\u6d9f\u6f2a\u3002\u82e5\u4ee3\u4ef7\u53ea\u662f\u5b64\u72ec\uff0c\u90a3\u5c31\u8ba9\u8fd9\u4efd\u613f\u671b\u8086\u610f\u6d41\u6dcc\u3002\n\u6d41\u5165\u5979\u6240\u6ce8\u89c6\u7684\u4e16\u95f4\uff0c\u4e5f\u6d41\u5165\u5979\u5982\u6e56\u6c34\u822c\u6f84\u6f88\u7684\u76ee\u5149\u3002\n</code></pre> Orador \u00c1udio de Entrada \u00c1udio Sintetizado Nahida (Genshin Impact) Zhongli (Genshin Impact) Furina (Genshin Impact) Orador Aleat\u00f3rio 1  -  Orador Aleat\u00f3rio 2  -"},{"location":"pt/samples/#frase-em-chines-2","title":"Frase em Chin\u00eas 2","text":"<pre><code>\u4f60\u4eec\u8fd9\u4e2a\u662f\u4ec0\u4e48\u7fa4\u554a\uff0c\u4f60\u4eec\u8fd9\u662f\u5bb3\u4eba\u4e0d\u6d45\u554a\u4f60\u4eec\u8fd9\u4e2a\u7fa4\uff01\u8c01\u662f\u7fa4\u4e3b\uff0c\u51fa\u6765\uff01\u771f\u7684\u592a\u8fc7\u5206\u4e86\u3002\u4f60\u4eec\u641e\u8fd9\u4e2a\u7fa4\u5e72\u4ec0\u4e48\uff1f\n\u6211\u513f\u5b50\u6bcf\u4e00\u79d1\u7684\u6210\u7ee9\u90fd\u4e0d\u8fc7\u90a3\u4e2a\u5e73\u5747\u5206\u5450\uff0c\u4ed6\u73b0\u5728\u521d\u4e8c\uff0c\u4f60\u53eb\u6211\u513f\u5b50\u600e\u4e48\u529e\u554a\uff1f\u4ed6\u73b0\u5728\u8fd8\u4e0d\u5230\u9ad8\u4e2d\u554a\uff1f\n\u4f60\u4eec\u5bb3\u6b7b\u6211\u513f\u5b50\u4e86\uff01\u5feb\u70b9\u51fa\u6765\u4f60\u8fd9\u4e2a\u7fa4\u4e3b\uff01\u518d\u8fd9\u6837\u6211\u53bb\u62a5\u8b66\u4e86\u554a\uff01\u6211\u8ddf\u4f60\u4eec\u8bf4\u4f60\u4eec\u8fd9\u4e00\u5e2e\u4eba\u554a\uff0c\u4e00\u5929\u5230\u665a\u554a\uff0c\n\u641e\u8fd9\u4e9b\u4ec0\u4e48\u6e38\u620f\u554a\uff0c\u52a8\u6f2b\u554a\uff0c\u4f1a\u5bb3\u6b7b\u4f60\u4eec\u7684\uff0c\u4f60\u4eec\u6ca1\u6709\u524d\u9014\u6211\u8ddf\u4f60\u8bf4\u3002\u4f60\u4eec\u8fd9\u4e5d\u767e\u591a\u4e2a\u4eba\uff0c\u597d\u597d\u5b66\u4e60\u4e0d\u597d\u5417\uff1f\n\u4e00\u5929\u5230\u665a\u5728\u4e0a\u7f51\u3002\u6709\u4ec0\u4e48\u610f\u601d\u554a\uff1f\u9ebb\u70e6\u4f60\u91cd\u89c6\u4e00\u4e0b\u4f60\u4eec\u7684\u751f\u6d3b\u7684\u76ee\u6807\u554a\uff1f\u6709\u4e00\u70b9\u5b66\u4e60\u76ee\u6807\u884c\u4e0d\u884c\uff1f\u4e00\u5929\u5230\u665a\u4e0a\u7f51\u662f\u4e0d\u662f\u4eba\u554a\uff1f\n</code></pre> Orador \u00c1udio de Entrada \u00c1udio Sintetizado Nahida (Genshin Impact) Orador Aleat\u00f3rio  -"},{"location":"pt/samples/#frase-em-chines-3","title":"Frase em Chin\u00eas 3","text":"<pre><code>\u5927\u5bb6\u597d\uff0c\u6211\u662f Fish Audio \u5f00\u53d1\u7684\u5f00\u6e90\u6587\u672c\u8f6c\u8bed\u97f3\u6a21\u578b\u3002\u7ecf\u8fc7\u5341\u4e94\u4e07\u5c0f\u65f6\u7684\u6570\u636e\u8bad\u7ec3\uff0c\n\u6211\u5df2\u7ecf\u80fd\u591f\u719f\u7ec3\u638c\u63e1\u4e2d\u6587\u3001\u65e5\u8bed\u548c\u82f1\u8bed\uff0c\u6211\u7684\u8bed\u8a00\u5904\u7406\u80fd\u529b\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0c\u58f0\u97f3\u8868\u73b0\u5f62\u5f0f\u4e30\u5bcc\u591a\u53d8\u3002\n\u4f5c\u4e3a\u4e00\u4e2a\u4ec5\u6709\u4ebf\u7ea7\u53c2\u6570\u7684\u6a21\u578b\uff0c\u6211\u76f8\u4fe1\u793e\u533a\u6210\u5458\u80fd\u591f\u5728\u4e2a\u4eba\u8bbe\u5907\u4e0a\u8f7b\u677e\u8fd0\u884c\u548c\u5fae\u8c03\uff0c\u8ba9\u6211\u6210\u4e3a\u60a8\u7684\u79c1\u4eba\u8bed\u97f3\u52a9\u624b\u3002\n</code></pre> Orador \u00c1udio de Entrada \u00c1udio Sintetizado Orador Aleat\u00f3rio  -"},{"location":"pt/samples/#frase-em-ingles-1","title":"Frase em Ingl\u00eas 1","text":"<pre><code>In the realm of advanced technology, the evolution of artificial intelligence stands as a \nmonumental achievement. This dynamic field, constantly pushing the boundaries of what \nmachines can do, has seen rapid growth and innovation. From deciphering complex data \npatterns to driving cars autonomously, AI's applications are vast and diverse.\n</code></pre> Orador \u00c1udio de Entrada \u00c1udio Sintetizado Orador Aleat\u00f3rio 1  -  Orador Aleat\u00f3rio 2  -"},{"location":"pt/samples/#frase-em-ingles-2","title":"Frase em Ingl\u00eas 2","text":"<pre><code>Hello everyone, I am an open-source text-to-speech model developed by \nFish Audio. After training with 150,000 hours of data, I have become proficient \nin Chinese, Japanese, and English, and my language processing abilities \nare close to human level. My voice is capable of a wide range of expressions. \nAs a model with only hundreds of millions of parameters, I believe community \nmembers can easily run and fine-tune me on their personal devices, allowing \nme to serve as your personal voice assistant.\n</code></pre> Orador \u00c1udio de Entrada \u00c1udio Sintetizado Orador Aleat\u00f3rio  -"},{"location":"pt/samples/#frase-em-japones-1","title":"Frase em Japon\u00eas 1","text":"<pre><code>\u5148\u9032\u6280\u8853\u306e\u9818\u57df\u306b\u304a\u3044\u3066\u3001\u4eba\u5de5\u77e5\u80fd\u306e\u9032\u5316\u306f\u753b\u671f\u7684\u306a\u6210\u679c\u3068\u3057\u3066\u7acb\u3063\u3066\u3044\u307e\u3059\u3002\u5e38\u306b\u6a5f\u68b0\u304c\u3067\u304d\u308b\u3053\u3068\u306e\u9650\u754c\u3092\n\u62bc\u3057\u5e83\u3052\u3066\u3044\u308b\u3053\u306e\u30c0\u30a4\u30ca\u30df\u30c3\u30af\u306a\u5206\u91ce\u306f\u3001\u6025\u901f\u306a\u6210\u9577\u3068\u9769\u65b0\u3092\u898b\u305b\u3066\u3044\u307e\u3059\u3002\u8907\u96d1\u306a\u30c7\u30fc\u30bf\u30d1\u30bf\u30fc\u30f3\u306e\u89e3\u8aad\u304b\n\u3089\u81ea\u52d5\u904b\u8ee2\u8eca\u306e\u64cd\u7e26\u307e\u3067\u3001AI\u306e\u5fdc\u7528\u306f\u5e83\u7bc4\u56f2\u306b\u53ca\u3073\u307e\u3059\u3002\n</code></pre> Orador \u00c1udio de Entrada \u00c1udio Sintetizado Orador Aleat\u00f3rio 1  -  Orador Aleat\u00f3rio 2  -"},{"location":"pt/samples/#frase-em-japones-2","title":"Frase em Japon\u00eas 2","text":"<pre><code>\u7686\u3055\u3093\u3001\u3053\u3093\u306b\u3061\u306f\u3002\u79c1\u306f\u30d5\u30a3\u30c3\u30b7\u30e5\u30aa\u30fc\u30c7\u30a3\u30aa\u306b\u3088\u3063\u3066\u958b\u767a\u3055\u308c\u305f\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u306e\u30c6\n\u30ad\u30b9\u30c8\u304b\u3089\u97f3\u58f0\u3078\u306e\u5909\u63db\u30e2\u30c7\u30eb\u3067\u3059\u300215\u4e07\u6642\u9593\u306e\u30c7\u30fc\u30bf\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u7d4c\u3066\u3001\n\u4e2d\u56fd\u8a9e\u3001\u65e5\u672c\u8a9e\u3001\u82f1\u8a9e\u3092\u719f\u77e5\u3057\u3066\u304a\u308a\u3001\u8a00\u8a9e\u51e6\u7406\u80fd\u529b\u306f\u4eba\u9593\u306b\u8fd1\u3044\u30ec\u30d9\u30eb\u3067\u3059\u3002\n\u58f0\u306e\u8868\u73fe\u3082\u591a\u5f69\u3067\u8c4a\u304b\u3067\u3059\u3002\u6570\u5104\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6301\u3064\u3053\u306e\u30e2\u30c7\u30eb\u306f\u3001\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\n\u306e\u30e1\u30f3\u30d0\u30fc\u304c\u500b\u4eba\u306e\u30c7\u30d0\u30a4\u30b9\u3067\u7c21\u5358\u306b\u5b9f\u884c\u3057\u3001\u5fae\u8abf\u6574\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3068\n\u4fe1\u3058\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u79c1\u3092\u500b\u4eba\u306e\u97f3\u58f0\u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u3068\u3057\u3066\u6d3b\u7528\u3067\u304d\u307e\u3059\u3002\n</code></pre> Orador \u00c1udio de Entrada \u00c1udio Sintetizado Orador Aleat\u00f3rio  -"}]}